{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYppSaMzeRKfq4oW4FMHHe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhinavarorags/CoolStuff/blob/test/QuantHW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "m2NmJUYPyTNn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca70beca-8557-4d84-cf61-6f7008b2adc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stuff\n"
          ]
        }
      ],
      "source": [
        "print(\"stuff\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "url = 'https://raw.githubusercontent.com/abhinavarorags/CoolStuff/refs/heads/test/s.csv'\n",
        "url = 'https://raw.githubusercontent.com/abhinavarorags/CoolStuff/refs/heads/test/sample_data.csv'\n",
        "\n",
        "try:\n",
        "  df = pd.read_csv(url, sep=',')\n",
        "except pd.errors.ParserError as e:\n",
        "    print(f\"Error reading CSV: {e}\")\n",
        "df.head()\n",
        "print(\"Data loaded: \",f\"Len: {len(df)}, Shape: {df.shape[0]}, Index Size: {df.index.size}, Size/Columns: {df.size // df.columns.size}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9W2RqVz3yowG",
        "outputId": "6bf4e16c-e929-454c-c826-6e41fec4048f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded:  Len: 67048, Shape: 67048, Index Size: 67048, Size/Columns: 67048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_training = df.iloc[:40000]  # First 100 rows\n",
        "train_data = df_training\n",
        "df_test = df.iloc[40001:]     # Rows from index 100 onwards\n",
        "test_data = df_test.copy()"
      ],
      "metadata": {
        "id": "RMiOpn5h6wdL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN THIS CELL\n",
        "#This is the REAL Q-learning code but it runs slower\n",
        "#Also needs lots of GPU power\n",
        "#See image asking for 84 hours of runtime\n",
        "#https://github.com/abhinavarorags/CoolStuff/blob/test/QuantFury%20Q-learning%20Compute.png\n",
        "\n",
        "def foo():\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  import random\n",
        "\n",
        "  # Using the previously loaded train_data from '/mnt/data/training.csv'\n",
        "\n",
        "  # Q-learning parameters\n",
        "  initial_alpha = 0.5  # Initial learning rate\n",
        "  min_alpha = 0.01  # Minimum learning rate\n",
        "  alpha_decay = 0.995  # Decay rate for alpha\n",
        "\n",
        "  initial_epsilon = 1.0  # Initial exploration rate\n",
        "  min_epsilon = 0.01  # Minimum exploration rate\n",
        "  epsilon_decay = 0.995  # Decay rate for epsilon\n",
        "\n",
        "  gamma = 0.95  # Discount factor\n",
        "  num_episodes = 1000  # Number of episodes\n",
        "\n",
        "  # Define actions\n",
        "  ACTIONS = {0: 'Buy Long', 1: 'Sell Short', 2: 'Hold'}\n",
        "\n",
        "  # Initialize Q-table\n",
        "  q_table = np.zeros((len(train_data), len(ACTIONS)))\n",
        "\n",
        "  # Function to choose an action using epsilon-greedy strategy\n",
        "  def choose_action(state_index, epsilon):\n",
        "      if random.uniform(0, 1) < epsilon:\n",
        "          return random.choice(list(ACTIONS.keys()))  # Explore\n",
        "      else:\n",
        "          return np.argmax(q_table[state_index])  # Exploit\n",
        "\n",
        "  # Q-learning process\n",
        "  for episode in range(num_episodes):\n",
        "      alpha = max(min_alpha, initial_alpha * (alpha_decay ** episode))\n",
        "      epsilon = max(min_epsilon, initial_epsilon * (epsilon_decay ** episode))\n",
        "      total_reward = 0\n",
        "\n",
        "      for state_index in range(len(train_data) - 1):\n",
        "          current_state = train_data.iloc[state_index].values[:-1]  # Exclude Date\n",
        "          action = choose_action(state_index, epsilon)\n",
        "          reward = train_data.iloc[state_index + 1]['Close'] - train_data.iloc[state_index]['Close']\n",
        "          next_state_index = state_index + 1\n",
        "          best_future_q = np.max(q_table[next_state_index]) if next_state_index < len(train_data) else 0\n",
        "          q_table[state_index, action] += alpha * (reward + gamma * best_future_q - q_table[state_index, action])\n",
        "          total_reward += reward\n",
        "\n",
        "      if episode % 100 == 0:\n",
        "          print(f\"Episode: {episode}, Alpha: {alpha:.4f}, Epsilon: {epsilon:.4f}, Total Reward: {total_reward}\")\n",
        "\n",
        "  # Save the Q-table to CSV\n",
        "  q_table_df = pd.DataFrame(q_table, columns=ACTIONS.keys())\n",
        "  #q_table_df.to_csv('/mnt/data/q_table.csv', index=False)\n",
        "  print(\"Q-table training complete and saved as q_table.csv.\")\n",
        "\n",
        "if 1==1:\n",
        "  pass\n",
        "else:\n",
        "    foo()\n"
      ],
      "metadata": {
        "id": "F9EGZ2k3FOYA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dumbed down the code to only 'Close' Prices and 10 episodes\n",
        "print(\"Running Code on Training Data\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Using the previously loaded train_data from '/mnt/data/training.csv'\n",
        "\n",
        "# Q-learning parameters\n",
        "initial_alpha = 0.5  # Initial learning rate\n",
        "min_alpha = 0.01  # Minimum learning rate\n",
        "alpha_decay = 0.995  # Decay rate for alpha\n",
        "\n",
        "initial_epsilon = 1.0  # Initial exploration rate\n",
        "min_epsilon = 0.01  # Minimum exploration rate\n",
        "epsilon_decay = 0.995  # Decay rate for epsilon\n",
        "\n",
        "gamma = 0.95  # Discount factor\n",
        "# Reduce the number of episodes for demonstration\n",
        "num_episodes = 10  # Use a smaller number for quicker demonstration\n",
        "\n",
        "ACTIONS = {0: 'Buy Long', 1: 'Sell Short', 2: 'Hold'}\n",
        "\n",
        "# Convert necessary columns to NumPy arrays for faster access\n",
        "close_prices = train_data['Close'].values\n",
        "actions = np.array(list(ACTIONS.keys()))\n",
        "\n",
        "\n",
        "\n",
        "# Initialize Q-table\n",
        "q_table = np.zeros((len(close_prices) - 1, len(actions)))\n",
        "\n",
        "# Run the Q-learning algorithm with optimized data handling\n",
        "for episode in range(num_episodes):\n",
        "    alpha = max(min_alpha, initial_alpha * (alpha_decay ** episode))\n",
        "    epsilon = max(min_epsilon, initial_epsilon * (epsilon_decay ** episode))\n",
        "    total_reward = 0\n",
        "\n",
        "    for i in range(len(close_prices) - 1):\n",
        "        if random.uniform(0, 1) < epsilon:\n",
        "            action = random.choice(actions)\n",
        "        else:\n",
        "            action = actions[np.argmax(q_table[i])]\n",
        "\n",
        "        reward = close_prices[i + 1] - close_prices[i]\n",
        "        next_state_action_values = q_table[i + 1] if i + 1 < len(close_prices) - 1 else np.zeros(len(actions))\n",
        "        best_future_q = np.max(next_state_action_values)\n",
        "        q_table[i, action] += alpha * (reward + gamma * best_future_q - q_table[i, action])\n",
        "        total_reward += reward\n",
        "\n",
        "    print(f\"Episode: {episode}, Alpha: {alpha:.4f}, Epsilon: {epsilon:.4f}, Total Reward: {total_reward}\")\n",
        "\n",
        "# Convert Q-table to DataFrame and save to CSV\n",
        "q_table_df = pd.DataFrame(q_table, columns=[str(action) for action in actions])\n",
        "#q_table_df.to_csv('/mnt/data/q_table_optimized.csv', index=False)\n",
        "print(\"Optimized Q-table training complete and saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4NYHCkKFjCP",
        "outputId": "b14ed831-53d8-4dfd-e1ea-1cd4f06a9539"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Code on Training Data\n",
            "Episode: 0, Alpha: 0.5000, Epsilon: 1.0000, Total Reward: -6.469999999999999\n",
            "Episode: 1, Alpha: 0.4975, Epsilon: 0.9950, Total Reward: -6.469999999999999\n",
            "Episode: 2, Alpha: 0.4950, Epsilon: 0.9900, Total Reward: -6.469999999999999\n",
            "Episode: 3, Alpha: 0.4925, Epsilon: 0.9851, Total Reward: -6.469999999999999\n",
            "Episode: 4, Alpha: 0.4901, Epsilon: 0.9801, Total Reward: -6.469999999999999\n",
            "Episode: 5, Alpha: 0.4876, Epsilon: 0.9752, Total Reward: -6.469999999999999\n",
            "Episode: 6, Alpha: 0.4852, Epsilon: 0.9704, Total Reward: -6.469999999999999\n",
            "Episode: 7, Alpha: 0.4828, Epsilon: 0.9655, Total Reward: -6.469999999999999\n",
            "Episode: 8, Alpha: 0.4803, Epsilon: 0.9607, Total Reward: -6.469999999999999\n",
            "Episode: 9, Alpha: 0.4779, Epsilon: 0.9559, Total Reward: -6.469999999999999\n",
            "Optimized Q-table training complete and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_table=q_table_df #Reassigned from pandas data frame to numpy array Hack\n",
        "test_data_orig = test_data.copy()\n",
        "print(\"Running Code on Test Data\")\n",
        "\n",
        "# Extracting Close prices from the test data for action determination\n",
        "close_prices_test = test_data['Close'].values\n",
        "\n",
        "# Preparing the output DataFrame\n",
        "recommended_actions = []\n",
        "\n",
        "# Determine the best action for each state based on the Q-table\n",
        "for i in range(len(close_prices_test) - 1):\n",
        "    state_index = i % len(q_table)  # Looping through Q-table if test data is longer than Q-table\n",
        "    action_index = np.argmax(q_table.iloc[state_index])\n",
        "    recommended_actions.append(ACTIONS[action_index])\n",
        "\n",
        "# Adding recommended actions to the test data\n",
        "test_data['Recommended Action'] = recommended_actions + ['N/A']  # Last entry has no subsequent state\n",
        "\n",
        "# Save the results with recommendations\n",
        "#test_data.to_csv('/mnt/data/test_with_actions.csv', index=False)\n",
        "print(\"Test Data saved with recommendations\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oxk8mPT9HdVc",
        "outputId": "5301951f-8fe5-49a6-ff33-565dcc29b92e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Code on Test Data\n",
            "Test Data saved with recommendations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test_data.iloc[4:5]\n",
        "test_with_actions = test_data\n",
        "test_data = test_data_orig\n",
        "print(\"Test data with recommendations loaded: \",f\"Len: {len(test_with_actions)}, Shape: {test_with_actions.shape[0]}, Index Size: {test_with_actions.index.size}, Size/Columns: {test_with_actions.size // test_with_actions.columns.size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jDULHytItoY",
        "outputId": "afb97c8c-b690-40d8-8eb6-bce00d5f0f73"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test data with recommendations loaded:  Len: 27047, Shape: 27047, Index Size: 27047, Size/Columns: 27047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load necessary libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming you have loaded 'test_with_actions' as follows\n",
        "#test_with_actions = pd.read_csv('path_to_test_with_actions.csv')\n",
        "\n",
        "# Define threshold for 'Hold' minimal change\n",
        "threshold = 0.005\n",
        "\n",
        "# Calculate correct and wrong predictions for 'Buy Long'\n",
        "correct_buy_long = test_with_actions[(test_with_actions['Recommended Action'] == 'Buy Long') & (test_with_actions['Close'] > test_with_actions['Open'])]\n",
        "wrong_buy_long = test_with_actions[(test_with_actions['Recommended Action'] == 'Buy Long') & (test_with_actions['Close'] <= test_with_actions['Open'])]\n",
        "\n",
        "# Calculate correct and wrong predictions for 'Sell Short'\n",
        "correct_sell_short = test_with_actions[(test_with_actions['Recommended Action'] == 'Sell Short') & (test_with_actions['Close'] < test_with_actions['Open'])]\n",
        "wrong_sell_short = test_with_actions[(test_with_actions['Recommended Action'] == 'Sell Short') & (test_with_actions['Close'] >= test_with_actions['Open'])]\n",
        "\n",
        "# Calculate correct and wrong predictions for 'Hold'\n",
        "correct_hold = test_with_actions[(test_with_actions['Recommended Action'] == 'Hold') & (abs(test_with_actions['Close'] - test_with_actions['Open']) / test_with_actions['Open'] < threshold)]\n",
        "wrong_hold = test_with_actions[(test_with_actions['Recommended Action'] == 'Hold') & (abs(test_with_actions['Close'] - test_with_actions['Open']) / test_with_actions['Open'] >= threshold)]\n",
        "\n",
        "# Compile results into a DataFrame\n",
        "results = {\n",
        "    \"Buy Long\": {\"Correct\": len(correct_buy_long), \"Wrong\": len(wrong_buy_long)},\n",
        "    \"Sell Short\": {\"Correct\": len(correct_sell_short), \"Wrong\": len(wrong_sell_short)},\n",
        "    \"Hold\": {\"Correct\": len(correct_hold), \"Wrong\": len(wrong_hold)}\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(results).transpose()\n",
        "results_df.columns = ['Correct Predictions', 'Wrong Predictions']\n",
        "\n",
        "# Display the results DataFrame\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zc7qg9knJS1N",
        "outputId": "80f4fa15-ae9c-4332-8e0d-78f343c97663"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Correct Predictions  Wrong Predictions\n",
            "Buy Long                   4421               4466\n",
            "Sell Short                 4383               4637\n",
            "Hold                       7446               1659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BS3Pa2FG4fZ4"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}