{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHpGoyAaXbE2gsW6INZ7gu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhinavarorags/CoolStuff/blob/test/QuantHW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "m2NmJUYPyTNn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca70beca-8557-4d84-cf61-6f7008b2adc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stuff\n"
          ]
        }
      ],
      "source": [
        "print(\"stuff\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "url = 'https://raw.githubusercontent.com/abhinavarorags/CoolStuff/refs/heads/test/s.csv'\n",
        "url = 'https://raw.githubusercontent.com/abhinavarorags/CoolStuff/refs/heads/test/sample_data.csv'\n",
        "\n",
        "try:\n",
        "  df = pd.read_csv(url, sep=',')\n",
        "except pd.errors.ParserError as e:\n",
        "    print(f\"Error reading CSV: {e}\")\n",
        "df.head()\n",
        "print(\"Data loaded: \",f\"Len: {len(df)}, Shape: {df.shape[0]}, Index Size: {df.index.size}, Size/Columns: {df.size // df.columns.size}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9W2RqVz3yowG",
        "outputId": "6bf4e16c-e929-454c-c826-6e41fec4048f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded:  Len: 67048, Shape: 67048, Index Size: 67048, Size/Columns: 67048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_training = df.iloc[:40000]  # First 100 rows\n",
        "train_data = df_training\n",
        "df_test = df.iloc[40001:]     # Rows from index 100 onwards\n",
        "test_data = df_test.copy()"
      ],
      "metadata": {
        "id": "RMiOpn5h6wdL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN THIS CELL\n",
        "#This is the REAL Q-learning code but it runs slower\n",
        "#Also needs lots of GPU power\n",
        "#See image asking for 84 hours of runtime\n",
        "#https://github.com/abhinavarorags/CoolStuff/blob/test/QuantFury%20Q-learning%20Compute.png\n",
        "\n",
        "def foo():\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  import random\n",
        "\n",
        "  # Using the previously loaded train_data from '/mnt/data/training.csv'\n",
        "\n",
        "  # Q-learning parameters\n",
        "  initial_alpha = 0.5  # Initial learning rate\n",
        "  min_alpha = 0.01  # Minimum learning rate\n",
        "  alpha_decay = 0.995  # Decay rate for alpha\n",
        "\n",
        "  initial_epsilon = 1.0  # Initial exploration rate\n",
        "  min_epsilon = 0.01  # Minimum exploration rate\n",
        "  epsilon_decay = 0.995  # Decay rate for epsilon\n",
        "\n",
        "  gamma = 0.95  # Discount factor\n",
        "  num_episodes = 1000  # Number of episodes\n",
        "\n",
        "  # Define actions\n",
        "  ACTIONS = {0: 'Buy Long', 1: 'Sell Short', 2: 'Hold'}\n",
        "\n",
        "  # Initialize Q-table\n",
        "  q_table = np.zeros((len(train_data), len(ACTIONS)))\n",
        "\n",
        "  # Function to choose an action using epsilon-greedy strategy\n",
        "  def choose_action(state_index, epsilon):\n",
        "      if random.uniform(0, 1) < epsilon:\n",
        "          return random.choice(list(ACTIONS.keys()))  # Explore\n",
        "      else:\n",
        "          return np.argmax(q_table[state_index])  # Exploit\n",
        "\n",
        "  # Q-learning process\n",
        "  for episode in range(num_episodes):\n",
        "      alpha = max(min_alpha, initial_alpha * (alpha_decay ** episode))\n",
        "      epsilon = max(min_epsilon, initial_epsilon * (epsilon_decay ** episode))\n",
        "      total_reward = 0\n",
        "\n",
        "      for state_index in range(len(train_data) - 1):\n",
        "          current_state = train_data.iloc[state_index].values[:-1]  # Exclude Date\n",
        "          action = choose_action(state_index, epsilon)\n",
        "          reward = train_data.iloc[state_index + 1]['Close'] - train_data.iloc[state_index]['Close']\n",
        "          next_state_index = state_index + 1\n",
        "          best_future_q = np.max(q_table[next_state_index]) if next_state_index < len(train_data) else 0\n",
        "          q_table[state_index, action] += alpha * (reward + gamma * best_future_q - q_table[state_index, action])\n",
        "          total_reward += reward\n",
        "\n",
        "      if episode % 100 == 0:\n",
        "          print(f\"Episode: {episode}, Alpha: {alpha:.4f}, Epsilon: {epsilon:.4f}, Total Reward: {total_reward}\")\n",
        "\n",
        "  # Save the Q-table to CSV\n",
        "  q_table_df = pd.DataFrame(q_table, columns=ACTIONS.keys())\n",
        "  #q_table_df.to_csv('/mnt/data/q_table.csv', index=False)\n",
        "  print(\"Q-table training complete and saved as q_table.csv.\")\n",
        "\n",
        "if 1==1:\n",
        "  pass\n",
        "else:\n",
        "    foo()\n"
      ],
      "metadata": {
        "id": "F9EGZ2k3FOYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dumbed down the code to only 'Close' Prices and 100 episodes\n",
        "print(\"Running Code on Training Data\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Using the previously loaded train_data from '/mnt/data/training.csv'\n",
        "\n",
        "# Q-learning parameters\n",
        "initial_alpha = 0.5  # Initial learning rate\n",
        "min_alpha = 0.01  # Minimum learning rate\n",
        "alpha_decay = 0.995  # Decay rate for alpha\n",
        "\n",
        "initial_epsilon = 1.0  # Initial exploration rate\n",
        "min_epsilon = 0.01  # Minimum exploration rate\n",
        "epsilon_decay = 0.995  # Decay rate for epsilon\n",
        "\n",
        "gamma = 0.95  # Discount factor\n",
        "# Reduce the number of episodes for demonstration\n",
        "num_episodes = 100  # Use a smaller number for quicker demonstration\n",
        "\n",
        "ACTIONS = {0: 'Buy Long', 1: 'Sell Short', 2: 'Hold'}\n",
        "\n",
        "# Convert necessary columns to NumPy arrays for faster access\n",
        "close_prices = train_data['Close'].values\n",
        "actions = np.array(list(ACTIONS.keys()))\n",
        "\n",
        "\n",
        "\n",
        "# Initialize Q-table\n",
        "q_table = np.zeros((len(close_prices) - 1, len(actions)))\n",
        "\n",
        "# Run the Q-learning algorithm with optimized data handling\n",
        "for episode in range(num_episodes):\n",
        "    alpha = max(min_alpha, initial_alpha * (alpha_decay ** episode))\n",
        "    epsilon = max(min_epsilon, initial_epsilon * (epsilon_decay ** episode))\n",
        "    total_reward = 0\n",
        "\n",
        "    for i in range(len(close_prices) - 1):\n",
        "        if random.uniform(0, 1) < epsilon:\n",
        "            action = random.choice(actions)\n",
        "        else:\n",
        "            action = actions[np.argmax(q_table[i])]\n",
        "\n",
        "        reward = close_prices[i + 1] - close_prices[i]\n",
        "        next_state_action_values = q_table[i + 1] if i + 1 < len(close_prices) - 1 else np.zeros(len(actions))\n",
        "        best_future_q = np.max(next_state_action_values)\n",
        "        q_table[i, action] += alpha * (reward + gamma * best_future_q - q_table[i, action])\n",
        "        total_reward += reward\n",
        "\n",
        "    print(f\"Episode: {episode}, Alpha: {alpha:.4f}, Epsilon: {epsilon:.4f}, Total Reward: {total_reward}\")\n",
        "    # Print the Q-table after each episode to see if it's updating\n",
        "    if episode % 1 == 0:  # Modify to control how often you see the output\n",
        "        print(f\"After Episode {episode}: Q-Table Sample:\")\n",
        "        print(q_table[:5])  # Print first few rows of the Q-table to check updates\n",
        "\n",
        "\n",
        "# Convert Q-table to DataFrame and save to CSV\n",
        "q_table_df = pd.DataFrame(q_table, columns=[str(action) for action in actions])\n",
        "#q_table_df.to_csv('/mnt/data/q_table_optimized.csv', index=False)\n",
        "print(\"Optimized Q-table training complete and saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Z4NYHCkKFjCP",
        "outputId": "2651fe97-eddf-48ec-f710-ee88756b8936"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Code on Training Data\n",
            "Episode: 0, Alpha: 0.5000, Epsilon: 1.0000, Total Reward: -6.469999999999999\n",
            "After Episode 0: Q-Table Sample:\n",
            "[[ 0.     0.3    0.   ]\n",
            " [ 0.     0.    -0.265]\n",
            " [-0.16   0.     0.   ]\n",
            " [ 0.     0.475  0.   ]\n",
            " [ 0.    -0.24   0.   ]]\n",
            "Episode: 1, Alpha: 0.4975, Epsilon: 0.9950, Total Reward: -6.469999999999999\n",
            "After Episode 1: Q-Table Sample:\n",
            "[[ 0.          0.44925     0.        ]\n",
            " [ 0.         -0.263675   -0.265     ]\n",
            " [-0.16        0.06529688  0.        ]\n",
            " [ 0.          0.7113125   0.        ]\n",
            " [ 0.         -0.3594      0.        ]]\n",
            "Episode: 2, Alpha: 0.4950, Epsilon: 0.9900, Total Reward: -6.469999999999999\n",
            "After Episode 2: Q-Table Sample:\n",
            "[[ 0.          0.52387313  0.        ]\n",
            " [-0.23164999 -0.263675   -0.265     ]\n",
            " [-0.16        0.06529688  0.17609915]\n",
            " [ 0.          0.8294658   0.        ]\n",
            " [-0.237606   -0.3594      0.        ]]\n",
            "Episode: 3, Alpha: 0.4925, Epsilon: 0.9851, Total Reward: -6.469999999999999\n",
            "After Episode 3: Q-Table Sample:\n",
            "[[ 0.          0.45297699  0.        ]\n",
            " [-0.29619989 -0.263675   -0.265     ]\n",
            " [-0.16        0.26363955  0.17609915]\n",
            " [ 0.46791057  0.8294658   0.        ]\n",
            " [-0.237606   -0.45045304  0.        ]]\n",
            "Episode: 4, Alpha: 0.4901, Epsilon: 0.9801, Total Reward: -6.469999999999999\n",
            "After Episode 4: Q-Table Sample:\n",
            "[[ 0.          0.40226982  0.        ]\n",
            " [-0.29619989 -0.263675   -0.27212688]\n",
            " [-0.16        0.36378777  0.17609915]\n",
            " [ 0.70417042  0.8294658   0.        ]\n",
            " [-0.38789194 -0.45045304  0.        ]]\n",
            "Episode: 5, Alpha: 0.4876, Epsilon: 0.9752, Total Reward: -6.469999999999999\n",
            "After Episode 5: Q-Table Sample:\n",
            "[[ 0.          0.40226982  0.17042899]\n",
            " [-0.24168433 -0.263675   -0.27212688]\n",
            " [-0.16        0.41460054  0.17609915]\n",
            " [ 0.70417042  0.88824121  0.        ]\n",
            " [-0.38789194 -0.49619814  0.        ]]\n",
            "Episode: 6, Alpha: 0.4852, Epsilon: 0.9704, Total Reward: -6.469999999999999\n",
            "After Episode 6: Q-Table Sample:\n",
            "[[ 0.          0.38680697  0.17042899]\n",
            " [-0.19047057 -0.263675   -0.27212688]\n",
            " [-0.16        0.41460054  0.34481297]\n",
            " [ 0.82344356  0.88824121  0.        ]\n",
            " [-0.46061058 -0.49619814  0.        ]]\n",
            "Episode: 7, Alpha: 0.4828, Epsilon: 0.9655, Total Reward: -6.469999999999999\n",
            "After Episode 7: Q-Table Sample:\n",
            "[[ 0.20230214  0.38680697  0.17042899]\n",
            " [-0.19047057 -0.20210109 -0.27212688]\n",
            " [ 0.17012558  0.41460054  0.34481297]\n",
            " [ 0.88453999  0.88824121  0.        ]\n",
            " [-0.46061058 -0.50035792  0.        ]]\n",
            "Episode: 8, Alpha: 0.4803, Epsilon: 0.9607, Total Reward: -6.469999999999999\n",
            "After Episode 8: Q-Table Sample:\n",
            "[[ 0.30641764  0.38680697  0.17042899]\n",
            " [-0.19047057 -0.17041186 -0.27212688]\n",
            " [ 0.17012558  0.46706812  0.34481297]\n",
            " [ 0.88453999  0.91790683  0.        ]\n",
            " [-0.46061058 -0.50035792 -0.18439768]]\n",
            "Episode: 9, Alpha: 0.4779, Epsilon: 0.9559, Total Reward: -6.469999999999999\n",
            "After Episode 9: Q-Table Sample:\n",
            "[[ 0.36935872  0.38680697  0.17042899]\n",
            " [-0.19047057 -0.130204   -0.27212688]\n",
            " [ 0.17012558  0.46706812  0.44384242]\n",
            " [ 0.88453999  0.91790683  0.37032223]\n",
            " [-0.46061058 -0.50035792 -0.27974147]]\n",
            "Episode: 10, Alpha: 0.4756, Epsilon: 0.9511, Total Reward: -6.469999999999999\n",
            "After Episode 10: Q-Table Sample:\n",
            "[[ 0.36935872  0.38680697  0.31589045]\n",
            " [-0.19047057 -0.10931823 -0.27212688]\n",
            " [ 0.17012558  0.50746337  0.44384242]\n",
            " [ 0.78928898  0.91790683  0.37032223]\n",
            " [-0.46061058 -0.40680709 -0.27974147]]\n",
            "Episode: 11, Alpha: 0.4732, Epsilon: 0.9464, Total Reward: -6.469999999999999\n",
            "After Episode 11: Q-Table Sample:\n",
            "[[ 0.42935237  0.38680697  0.31589045]\n",
            " [-0.12301405 -0.10931823 -0.27212688]\n",
            " [ 0.17012558  0.52854253  0.44384242]\n",
            " [ 0.78928898  0.91790683  0.51886364]\n",
            " [-0.38633504 -0.40680709 -0.27974147]]\n",
            "Episode: 12, Alpha: 0.4708, Epsilon: 0.9416, Total Reward: -6.469999999999999\n",
            "After Episode 12: Q-Table Sample:\n",
            "[[ 0.42935237  0.38680697  0.40075761]\n",
            " [-0.12301405 -0.10931823 -0.15713483]\n",
            " [ 0.34992182  0.52854253  0.44384242]\n",
            " [ 0.78928898  0.91790683  0.59672736]\n",
            " [-0.38633504 -0.40680709 -0.24097776]]\n",
            "Episode: 13, Alpha: 0.4685, Epsilon: 0.9369, Total Reward: -6.469999999999999\n",
            "After Episode 13: Q-Table Sample:\n",
            "[[ 0.42935237  0.43802843  0.40075761]\n",
            " [-0.12301405 -0.10931823 -0.09658661]\n",
            " [ 0.34992182  0.53953674  0.44384242]\n",
            " [ 0.78928898  0.91790683  0.65497711]\n",
            " [-0.28295161 -0.40680709 -0.24097776]]\n",
            "Episode: 14, Alpha: 0.4661, Epsilon: 0.9322, Total Reward: -6.469999999999999\n",
            "After Episode 14: Q-Table Sample:\n",
            "[[ 0.42935237  0.47075637  0.40075761]\n",
            " [-0.12301405 -0.10931823 -0.05969523]\n",
            " [ 0.34992182  0.53953674  0.49426165]\n",
            " [ 0.78928898  0.91790683  0.68578452]\n",
            " [-0.15363679 -0.40680709 -0.24097776]]\n",
            "Episode: 15, Alpha: 0.4638, Epsilon: 0.9276, Total Reward: -6.469999999999999\n",
            "After Episode 15: Q-Table Sample:\n",
            "[[ 0.42935237  0.47075637  0.4668617 ]\n",
            " [-0.12301405 -0.10931823 -0.04009796]\n",
            " [ 0.34992182  0.54532233  0.49426165]\n",
            " [ 0.78928898  0.91790683  0.74063192]\n",
            " [-0.04566581 -0.40680709 -0.24097776]]\n",
            "Episode: 16, Alpha: 0.4615, Epsilon: 0.9229, Total Reward: -6.469999999999999\n",
            "After Episode 16: Q-Table Sample:\n",
            "[[ 0.42935237  0.47075637  0.51072181]\n",
            " [-0.12301405 -0.10931823 -0.02710577]\n",
            " [ 0.44317924  0.54532233  0.49426165]\n",
            " [ 0.84343204  0.91790683  0.74063192]\n",
            " [-0.04566581 -0.18254659 -0.24097776]]\n",
            "Episode: 17, Alpha: 0.4592, Epsilon: 0.9183, Total Reward: -6.469999999999999\n",
            "After Episode 17: Q-Table Sample:\n",
            "[[ 0.42935237  0.5182761   0.51072181]\n",
            " [-0.12301405 -0.06460795 -0.02710577]\n",
            " [ 0.49315047  0.54532233  0.49426165]\n",
            " [ 0.84343204  0.91272323  0.74063192]\n",
            " [ 0.08211538 -0.18254659 -0.24097776]]\n",
            "Episode: 18, Alpha: 0.4569, Epsilon: 0.9137, Total Reward: -6.469999999999999\n",
            "After Episode 18: Q-Table Sample:\n",
            "[[ 0.42935237  0.54384825  0.51072181]\n",
            " [-0.12301405 -0.06460795 -0.02017883]\n",
            " [ 0.51779207  0.54532233  0.49426165]\n",
            " [ 0.84343204  0.96539325  0.74063192]\n",
            " [ 0.15087924 -0.18254659 -0.24097776]]\n",
            "Episode: 19, Alpha: 0.4546, Epsilon: 0.9092, Total Reward: -6.469999999999999\n",
            "After Episode 19: Q-Table Sample:\n",
            "[[ 0.42935237  0.5606594   0.51072181]\n",
            " [-0.12301405 -0.06460795 -0.01643536]\n",
            " [ 0.51779207  0.54532233  0.54102044]\n",
            " [ 0.95703259  0.96539325  0.74063192]\n",
            " [ 0.2394004  -0.18254659 -0.24097776]]\n",
            "Episode: 20, Alpha: 0.4523, Epsilon: 0.9046, Total Reward: -6.469999999999999\n",
            "After Episode 20: Q-Table Sample:\n",
            "[[ 0.49947508  0.5606594   0.51072181]\n",
            " [-0.12301405 -0.04078767 -0.01643536]\n",
            " [ 0.51779207  0.56875231  0.54102044]\n",
            " [ 0.95703259  1.06129875  0.74063192]\n",
            " [ 0.28744037 -0.18254659 -0.24097776]]\n",
            "Episode: 21, Alpha: 0.4500, Epsilon: 0.9001, Total Reward: -6.469999999999999\n",
            "After Episode 21: Q-Table Sample:\n",
            "[[ 0.49947508  0.5606594   0.5438741 ]\n",
            " [-0.06301029 -0.04078767 -0.01643536]\n",
            " [ 0.51779207  0.62252421  0.54102044]\n",
            " [ 0.95703259  1.13410214  0.74063192]\n",
            " [ 0.28744037  0.11324353 -0.24097776]]\n",
            "Episode: 22, Alpha: 0.4478, Epsilon: 0.8956, Total Reward: -6.469999999999999\n",
            "After Episode 22: Q-Table Sample:\n",
            "[[ 0.53749782  0.5606594   0.5438741 ]\n",
            " [-0.00730106 -0.04078767 -0.01643536]\n",
            " [ 0.62508562  0.62252421  0.54102044]\n",
            " [ 1.07616167  1.13410214  0.74063192]\n",
            " [ 0.28744037  0.11324353  0.07949851]]\n",
            "Episode: 23, Alpha: 0.4456, Epsilon: 0.8911, Total Reward: -6.469999999999999\n",
            "After Episode 23: Q-Table Sample:\n",
            "[[ 0.56225558  0.5606594   0.5438741 ]\n",
            " [-0.00730106  0.0058258  -0.01643536]\n",
            " [ 0.62508562  0.62252421  0.63742801]\n",
            " [ 1.07616167  1.13410214  0.95558366]\n",
            " [ 0.28744037  0.11324353  0.2948888 ]]\n",
            "Episode: 24, Alpha: 0.4433, Epsilon: 0.8867, Total Reward: -6.469999999999999\n",
            "After Episode 24: Q-Table Sample:\n",
            "[[ 0.58144229  0.5606594   0.5438741 ]\n",
            " [-0.00730106  0.03673933 -0.01643536]\n",
            " [ 0.62508562  0.62252421  0.69061349]\n",
            " [ 1.14442632  1.13410214  0.95558366]\n",
            " [ 0.46266164  0.11324353  0.2948888 ]]\n",
            "Episode: 25, Alpha: 0.4411, Epsilon: 0.8822, Total Reward: -6.469999999999999\n",
            "After Episode 25: Q-Table Sample:\n",
            "[[ 0.58144229  0.59340872  0.5438741 ]\n",
            " [ 0.05153592  0.03673933 -0.01643536]\n",
            " [ 0.68777592  0.62252421  0.69061349]\n",
            " [ 1.2525434   1.13410214  0.95558366]\n",
            " [ 0.60491897  0.11324353  0.2948888 ]]\n",
            "Episode: 26, Alpha: 0.4389, Epsilon: 0.8778, Total Reward: -6.469999999999999\n",
            "After Episode 26: Q-Table Sample:\n",
            "[[0.58144229 0.59340872 0.58999639]\n",
            " [0.05153592 0.03673933 0.04611652]\n",
            " [0.68777592 0.7311057  0.69061349]\n",
            " [1.2525434  1.13410214 1.20535958]\n",
            " [0.70894048 0.11324353 0.2948888 ]]\n",
            "Episode: 27, Alpha: 0.4367, Epsilon: 0.8734, Total Reward: -6.469999999999999\n",
            "After Episode 27: Q-Table Sample:\n",
            "[[0.61092757 0.59340872 0.58999639]\n",
            " [0.10089048 0.03673933 0.04611652]\n",
            " [0.68777592 0.7311057  0.7689168 ]\n",
            " [1.2525434  1.13410214 1.38796284]\n",
            " [0.80001991 0.11324353 0.2948888 ]]\n",
            "Episode: 28, Alpha: 0.4345, Epsilon: 0.8691, Total Reward: -6.469999999999999\n",
            "After Episode 28: Q-Table Sample:\n",
            "[[0.64782686 0.59340872 0.58999639]\n",
            " [0.10089048 0.10788506 0.04611652]\n",
            " [0.68777592 0.84732372 0.7689168 ]\n",
            " [1.45132863 1.13410214 1.38796284]\n",
            " [0.80001991 0.48104805 0.2948888 ]]\n",
            "Episode: 29, Alpha: 0.4324, Epsilon: 0.8647, Total Reward: -6.469999999999999\n",
            "After Episode 29: Q-Table Sample:\n",
            "[[0.64782686 0.64057078 0.58999639]\n",
            " [0.10089048 0.18011949 0.04611652]\n",
            " [0.68777592 0.93873997 0.7689168 ]\n",
            " [1.45132863 1.38310199 1.38796284]\n",
            " [0.80001991 0.48104805 0.59254381]]\n",
            "Episode: 30, Alpha: 0.4302, Epsilon: 0.8604, Total Reward: -6.469999999999999\n",
            "After Episode 30: Q-Table Sample:\n",
            "[[0.64782686 0.64057078 0.66791155]\n",
            " [0.10089048 0.18011949 0.18192233]\n",
            " [0.68777592 0.93873997 0.893606  ]\n",
            " [1.56261515 1.38310199 1.38796284]\n",
            " [0.80001991 0.48104805 0.77788011]]\n",
            "Episode: 31, Alpha: 0.4280, Epsilon: 0.8561, Total Reward: -6.469999999999999\n",
            "After Episode 31: Q-Table Sample:\n",
            "[[0.70133173 0.64057078 0.66791155]\n",
            " [0.21257176 0.18011949 0.18192233]\n",
            " [0.89182675 0.93873997 0.893606  ]\n",
            " [1.62571002 1.38310199 1.38796284]\n",
            " [0.80001991 0.48104805 0.90873187]]\n",
            "Episode: 32, Alpha: 0.4259, Epsilon: 0.8518, Total Reward: -6.469999999999999\n",
            "After Episode 32: Q-Table Sample:\n",
            "[[0.74418223 0.64057078 0.66791155]\n",
            " [0.21257176 0.18011949 0.25853366]\n",
            " [0.89182675 1.06041328 0.893606  ]\n",
            " [1.62571002 1.56632171 1.38796284]\n",
            " [0.80001991 0.7376666  0.90873187]]\n",
            "Episode: 33, Alpha: 0.4238, Epsilon: 0.8475, Total Reward: -6.469999999999999\n",
            "After Episode 33: Q-Table Sample:\n",
            "[[0.74418223 0.64057078 0.7432138 ]\n",
            " [0.32479527 0.18011949 0.25853366]\n",
            " [1.03277218 1.06041328 0.893606  ]\n",
            " [1.62571002 1.67098205 1.38796284]\n",
            " [0.80001991 0.7376666  0.98282715]]\n",
            "Episode: 34, Alpha: 0.4217, Epsilon: 0.8433, Total Reward: -6.469999999999999\n",
            "After Episode 34: Q-Table Sample:\n",
            "[[0.74418223 0.64057078 0.81293055]\n",
            " [0.38913834 0.18011949 0.25853366]\n",
            " [1.1317175  1.06041328 0.893606  ]\n",
            " [1.73448617 1.67098205 1.38796284]\n",
            " [0.91958339 0.7376666  0.98282715]]\n",
            "Episode: 35, Alpha: 0.4195, Epsilon: 0.8391, Total Reward: -6.469999999999999\n",
            "After Episode 35: Q-Table Sample:\n",
            "[[0.74418223 0.77864728 0.81293055]\n",
            " [0.38913834 0.18011949 0.3787742 ]\n",
            " [1.21396679 1.06041328 0.893606  ]\n",
            " [1.79708202 1.67098205 1.38796284]\n",
            " [0.98838688 0.7376666  0.98282715]]\n",
            "Episode: 36, Alpha: 0.4174, Epsilon: 0.8349, Total Reward: -6.469999999999999\n",
            "After Episode 36: Q-Table Sample:\n",
            "[[0.74418223 0.77864728 0.87836567]\n",
            " [0.48687515 0.18011949 0.3787742 ]\n",
            " [1.21396679 1.06041328 1.09966678]\n",
            " [1.83543931 1.67098205 1.38796284]\n",
            " [1.05530113 0.7376666  0.98282715]]\n",
            "Episode: 37, Alpha: 0.4154, Epsilon: 0.8307, Total Reward: -6.469999999999999\n",
            "After Episode 37: Q-Table Sample:\n",
            "[[0.74418223 0.8965612  0.87836567]\n",
            " [0.48687515 0.36418556 0.3787742 ]\n",
            " [1.30106788 1.06041328 1.09966678]\n",
            " [1.88407655 1.67098205 1.38796284]\n",
            " [1.1244751  0.7376666  0.98282715]]\n",
            "Episode: 38, Alpha: 0.4133, Epsilon: 0.8266, Total Reward: -6.469999999999999\n",
            "After Episode 38: Q-Table Sample:\n",
            "[[0.74418223 0.96515379 0.87836567]\n",
            " [0.57744162 0.36418556 0.3787742 ]\n",
            " [1.30106788 1.22963572 1.09966678]\n",
            " [1.88407655 1.81450239 1.38796284]\n",
            " [1.19268579 0.7376666  0.98282715]]\n",
            "Episode: 39, Alpha: 0.4112, Epsilon: 0.8224, Total Reward: -6.469999999999999\n",
            "After Episode 39: Q-Table Sample:\n",
            "[[0.74418223 1.0405773  0.87836567]\n",
            " [0.63031286 0.36418556 0.3787742 ]\n",
            " [1.30106788 1.22963572 1.25190144]\n",
            " [1.88407655 1.92493412 1.38796284]\n",
            " [1.2325061  0.7376666  0.98282715]]\n",
            "Episode: 40, Alpha: 0.4092, Epsilon: 0.8183, Total Reward: -6.469999999999999\n",
            "After Episode 40: Q-Table Sample:\n",
            "[[0.74418223 1.0405773  1.00947346]\n",
            " [0.66128694 0.36418556 0.3787742 ]\n",
            " [1.30106788 1.34381253 1.25190144]\n",
            " [1.88407655 1.92493412 1.6878436 ]\n",
            " [1.25583442 0.7376666  0.98282715]]\n",
            "Episode: 41, Alpha: 0.4071, Epsilon: 0.8142, Total Reward: -6.469999999999999\n",
            "After Episode 41: Q-Table Sample:\n",
            "[[0.74418223 1.0405773  1.09852935]\n",
            " [0.66128694 0.51988085 0.3787742 ]\n",
            " [1.30106788 1.41093545 1.25190144]\n",
            " [1.88407655 2.01372923 1.6878436 ]\n",
            " [1.25583442 0.7376666  1.10768669]]\n",
            "Episode: 42, Alpha: 0.4051, Epsilon: 0.8102, Total Reward: -6.469999999999999\n",
            "After Episode 42: Q-Table Sample:\n",
            "[[0.74418223 1.0405773  1.15106532]\n",
            " [0.72168487 0.51988085 0.3787742 ]\n",
            " [1.30106788 1.41093545 1.39009052]\n",
            " [1.98897822 2.01372923 1.6878436 ]\n",
            " [1.25583442 1.00114965 1.10768669]]\n",
            "Episode: 43, Alpha: 0.4031, Epsilon: 0.8061, Total Reward: -6.469999999999999\n",
            "After Episode 43: Q-Table Sample:\n",
            "[[0.74418223 1.13933476 1.15106532]\n",
            " [0.72168487 0.51988085 0.55273784]\n",
            " [1.30106788 1.4843344  1.39009052]\n",
            " [2.05107441 2.01372923 1.6878436 ]\n",
            " [1.25583442 1.15711758 1.10768669]]\n",
            "Episode: 44, Alpha: 0.4010, Epsilon: 0.8021, Total Reward: -6.469999999999999\n",
            "After Episode 44: Q-Table Sample:\n",
            "[[0.74418223 1.19799294 1.15106532]\n",
            " [0.72168487 0.51988085 0.68402961]\n",
            " [1.30106788 1.54215859 1.39009052]\n",
            " [2.05107441 2.06558885 1.6878436 ]\n",
            " [1.25583442 1.28234274 1.10768669]]\n",
            "Episode: 45, Alpha: 0.3990, Epsilon: 0.7981, Total Reward: -6.469999999999999\n",
            "After Episode 45: Q-Table Sample:\n",
            "[[0.74418223 1.23295128 1.15106532]\n",
            " [0.72168487 0.51988085 0.78419525]\n",
            " [1.43723445 1.54215859 1.39009052]\n",
            " [2.05107441 2.10654429 1.6878436 ]\n",
            " [1.34104219 1.28234274 1.10768669]]\n",
            "Episode: 46, Alpha: 0.3970, Epsilon: 0.7941, Total Reward: -6.469999999999999\n",
            "After Episode 46: Q-Table Sample:\n",
            "[[0.98272376 1.23295128 1.15106532]\n",
            " [0.72168487 0.51988085 0.84409053]\n",
            " [1.43723445 1.54215859 1.50567873]\n",
            " [2.05107441 2.15317469 1.6878436 ]\n",
            " [1.39199323 1.28234274 1.10768669]]\n",
            "Episode: 47, Alpha: 0.3951, Epsilon: 0.7901, Total Reward: -6.469999999999999\n",
            "After Episode 47: Q-Table Sample:\n",
            "[[0.98272376 1.29968937 1.15106532]\n",
            " [0.80597556 0.51988085 0.84409053]\n",
            " [1.43723445 1.61459437 1.50567873]\n",
            " [2.05107441 2.15317469 1.91877152]\n",
            " [1.45704946 1.28234274 1.10768669]]\n",
            "Episode: 48, Alpha: 0.3931, Epsilon: 0.7862, Total Reward: -6.469999999999999\n",
            "After Episode 48: Q-Table Sample:\n",
            "[[0.98272376 1.29968937 1.24965722]\n",
            " [0.80597556 0.51988085 0.9068941 ]\n",
            " [1.43723445 1.61459437 1.59209174]\n",
            " [2.05107441 2.15317469 2.08206581]\n",
            " [1.45704946 1.4107625  1.10768669]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-102007a358ef>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclose_prices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mclose_prices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mnext_state_action_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclose_prices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mbest_future_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state_action_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mq_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbest_future_q\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mq_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2808\u001b[0m     \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2809\u001b[0m     \"\"\"\n\u001b[0;32m-> 2810\u001b[0;31m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0m\u001b[1;32m   2811\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[1;32m   2812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_table=q_table_df #Reassigned from pandas data frame to numpy array Hack\n",
        "test_data_orig = test_data.copy()\n",
        "print(\"Running Code on Test Data\")\n",
        "\n",
        "# Extracting Close prices from the test data for action determination\n",
        "close_prices_test = test_data['Close'].values\n",
        "\n",
        "# Preparing the output DataFrame\n",
        "recommended_actions = []\n",
        "\n",
        "# Determine the best action for each state based on the Q-table\n",
        "for i in range(len(close_prices_test) - 1):\n",
        "    state_index = i % len(q_table)  # Looping through Q-table if test data is longer than Q-table\n",
        "    action_index = np.argmax(q_table.iloc[state_index])\n",
        "    recommended_actions.append(ACTIONS[action_index])\n",
        "\n",
        "# Adding recommended actions to the test data\n",
        "test_data['Recommended Action'] = recommended_actions + ['N/A']  # Last entry has no subsequent state\n",
        "\n",
        "# Save the results with recommendations\n",
        "#test_data.to_csv('/mnt/data/test_with_actions.csv', index=False)\n",
        "print(\"Test Data saved with recommendations\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oxk8mPT9HdVc",
        "outputId": "2a3b439f-23bc-4cfb-bae8-d1b49fde6f19"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Code on Test Data\n",
            "Test Data saved with recommendations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test_data.iloc[4:5]\n",
        "test_with_actions = test_data\n",
        "test_data = test_data_orig\n",
        "print(\"Test data with recommendations loaded: \",f\"Len: {len(test_with_actions)}, Shape: {test_with_actions.shape[0]}, Index Size: {test_with_actions.index.size}, Size/Columns: {test_with_actions.size // test_with_actions.columns.size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jDULHytItoY",
        "outputId": "697cea10-c7bb-42e3-c536-77fd6abdc250"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test data with recommendations loaded:  Len: 27047, Shape: 27047, Index Size: 27047, Size/Columns: 27047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load necessary libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming you have loaded 'test_with_actions' as follows\n",
        "#test_with_actions = pd.read_csv('path_to_test_with_actions.csv')\n",
        "\n",
        "# Define threshold for 'Hold' minimal change\n",
        "threshold = 0.005\n",
        "\n",
        "# Calculate correct and wrong predictions for 'Buy Long'\n",
        "correct_buy_long = test_with_actions[(test_with_actions['Recommended Action'] == 'Buy Long') & (test_with_actions['Close'] > test_with_actions['Open'])]\n",
        "wrong_buy_long = test_with_actions[(test_with_actions['Recommended Action'] == 'Buy Long') & (test_with_actions['Close'] <= test_with_actions['Open'])]\n",
        "\n",
        "# Calculate correct and wrong predictions for 'Sell Short'\n",
        "correct_sell_short = test_with_actions[(test_with_actions['Recommended Action'] == 'Sell Short') & (test_with_actions['Close'] < test_with_actions['Open'])]\n",
        "wrong_sell_short = test_with_actions[(test_with_actions['Recommended Action'] == 'Sell Short') & (test_with_actions['Close'] >= test_with_actions['Open'])]\n",
        "\n",
        "# Calculate correct and wrong predictions for 'Hold'\n",
        "correct_hold = test_with_actions[(test_with_actions['Recommended Action'] == 'Hold') & (abs(test_with_actions['Close'] - test_with_actions['Open']) / test_with_actions['Open'] < threshold)]\n",
        "wrong_hold = test_with_actions[(test_with_actions['Recommended Action'] == 'Hold') & (abs(test_with_actions['Close'] - test_with_actions['Open']) / test_with_actions['Open'] >= threshold)]\n",
        "\n",
        "# Compile results into a DataFrame\n",
        "results = {\n",
        "    \"Buy Long\": {\"Correct\": len(correct_buy_long), \"Wrong\": len(wrong_buy_long)},\n",
        "    \"Sell Short\": {\"Correct\": len(correct_sell_short), \"Wrong\": len(wrong_sell_short)},\n",
        "    \"Hold\": {\"Correct\": len(correct_hold), \"Wrong\": len(wrong_hold)}\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(results).transpose()\n",
        "results_df.columns = ['Correct Predictions', 'Wrong Predictions']\n",
        "\n",
        "# Display the results DataFrame\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zc7qg9knJS1N",
        "outputId": "65660759-4173-470f-9d19-8630a0ff1800"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Correct Predictions  Wrong Predictions\n",
            "Buy Long                   4555               4559\n",
            "Sell Short                 4393               4503\n",
            "Hold                       7395               1607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "def load_data(url):\n",
        "    # Load the training data from URL\n",
        "    try:\n",
        "        df = pd.read_csv(url, sep=',')\n",
        "    except pd.errors.ParserError as e:\n",
        "        print(f\"Error reading CSV: {e}\")\n",
        "        raise\n",
        "\n",
        "    df_training = df.iloc[:20000]  # First 20000 rows\n",
        "    df_test = df.iloc[20001:]  # Rows from index 20001 onwards\n",
        "    return df_training, df_test\n",
        "\n",
        "def train_q_learning(train_data, num_episodes=200):\n",
        "    # Q-learning parameters\n",
        "    initial_alpha = 0.5  # Initial learning rate\n",
        "    min_alpha = 0.01  # Minimum learning rate\n",
        "    alpha_decay = 0.995  # Decay rate for alpha\n",
        "\n",
        "    initial_epsilon = 1.0  # Initial exploration rate\n",
        "    min_epsilon = 0.01  # Minimum exploration rate\n",
        "    epsilon_decay = 0.995  # Decay rate for epsilon\n",
        "\n",
        "    gamma = 0.95  # Discount factor\n",
        "    ACTIONS = {0: 'Buy Long', 1: 'Sell Short', 2: 'Hold'}\n",
        "\n",
        "    # Convert necessary columns to NumPy arrays for faster access\n",
        "    close_prices = train_data['Close'].values\n",
        "    actions = np.array(list(ACTIONS.keys()))\n",
        "\n",
        "    # Initialize Q-table\n",
        "    q_table = np.zeros((len(close_prices) - 1, len(actions)))\n",
        "\n",
        "    # Run the Q-learning algorithm with optimized data handling\n",
        "    for episode in range(num_episodes):\n",
        "        alpha = max(min_alpha, initial_alpha * (alpha_decay ** episode))\n",
        "        epsilon = max(min_epsilon, initial_epsilon * (epsilon_decay ** episode))\n",
        "        total_reward = 0\n",
        "\n",
        "        for i in range(len(close_prices) - 1):\n",
        "            if random.uniform(0, 1) < epsilon:\n",
        "                action = random.choice(actions)\n",
        "            else:\n",
        "                action = actions[np.argmax(q_table[i])]\n",
        "\n",
        "            reward = close_prices[i + 1] - close_prices[i]\n",
        "            next_state_action_values = q_table[i + 1] if i + 1 < len(close_prices) - 1 else np.zeros(len(actions))\n",
        "            best_future_q = np.max(next_state_action_values)\n",
        "            q_table[i, action] += alpha * (reward + gamma * best_future_q - q_table[i, action])\n",
        "            total_reward += reward\n",
        "\n",
        "        print(f\"Episode: {episode}, Alpha: {alpha:.4f}, Epsilon: {epsilon:.4f}, Total Reward: {total_reward}\")\n",
        "        # Print the Q-table after each episode to see if it's updating\n",
        "        if episode % 1 == 0:  # Modify to control how often you see the output\n",
        "            print(f\"After Episode {episode}: Q-Table Sample:\")\n",
        "            print(q_table[:5])  # Print first few rows of the Q-table to check updates\n",
        "\n",
        "    return q_table\n",
        "\n",
        "def test_q_learning(test_data, q_table):\n",
        "    print(\"Running Code on Test Data\")\n",
        "\n",
        "    ACTIONS = {0: 'Buy Long', 1: 'Sell Short', 2: 'Hold'}\n",
        "    # Extracting Close prices from the test data for action determination\n",
        "    close_prices_test = test_data['Close'].values\n",
        "\n",
        "    # Preparing the output DataFrame\n",
        "    recommended_actions = []\n",
        "\n",
        "    # Determine the best action for each state based on the Q-table\n",
        "    for i in range(len(close_prices_test) - 1):\n",
        "        state_index = i % len(q_table)  # Looping through Q-table if test data is longer than Q-table\n",
        "        action_index = np.argmax(q_table[state_index])\n",
        "        recommended_actions.append(ACTIONS[action_index])\n",
        "\n",
        "    # Adding recommended actions to the test data\n",
        "    test_data['Recommended Action'] = recommended_actions + ['N/A']  # Last entry has no subsequent state\n",
        "\n",
        "    # Save the results with recommendations\n",
        "    # test_data.to_csv('/mnt/data/test_with_actions.csv', index=False)\n",
        "    print(\"Test Data saved with recommendations\")\n",
        "    return test_data\n",
        "\n",
        "def performanceAnalyse(test_data_with_actions):\n",
        "    # Assuming you have loaded 'test_with_actions' as follows\n",
        "    #test_with_actions = pd.read_csv('path_to_test_with_actions.csv')\n",
        "\n",
        "    # Define threshold for 'Hold' minimal change\n",
        "    threshold = 0.005\n",
        "\n",
        "    # Calculate correct and wrong predictions for 'Buy Long'\n",
        "    correct_buy_long = test_with_actions[(test_with_actions['Recommended Action'] == 'Buy Long') & (test_with_actions['Close'] > test_with_actions['Open'])]\n",
        "    wrong_buy_long = test_with_actions[(test_with_actions['Recommended Action'] == 'Buy Long') & (test_with_actions['Close'] <= test_with_actions['Open'])]\n",
        "\n",
        "    # Calculate correct and wrong predictions for 'Sell Short'\n",
        "    correct_sell_short = test_with_actions[(test_with_actions['Recommended Action'] == 'Sell Short') & (test_with_actions['Close'] < test_with_actions['Open'])]\n",
        "    wrong_sell_short = test_with_actions[(test_with_actions['Recommended Action'] == 'Sell Short') & (test_with_actions['Close'] >= test_with_actions['Open'])]\n",
        "\n",
        "    # Calculate correct and wrong predictions for 'Hold'\n",
        "    correct_hold = test_with_actions[(test_with_actions['Recommended Action'] == 'Hold') & (abs(test_with_actions['Close'] - test_with_actions['Open']) / test_with_actions['Open'] < threshold)]\n",
        "    wrong_hold = test_with_actions[(test_with_actions['Recommended Action'] == 'Hold') & (abs(test_with_actions['Close'] - test_with_actions['Open']) / test_with_actions['Open'] >= threshold)]\n",
        "\n",
        "    # Compile results into a DataFrame\n",
        "    results = {\n",
        "        \"Buy Long\": {\"Correct\": len(correct_buy_long), \"Wrong\": len(wrong_buy_long)},\n",
        "        \"Sell Short\": {\"Correct\": len(correct_sell_short), \"Wrong\": len(wrong_sell_short)},\n",
        "        \"Hold\": {\"Correct\": len(correct_hold), \"Wrong\": len(wrong_hold)}\n",
        "    }\n",
        "\n",
        "    results_df = pd.DataFrame(results).transpose()\n",
        "    results_df.columns = ['Correct Predictions', 'Wrong Predictions']\n",
        "\n",
        "    # Display the results DataFrame\n",
        "    print(results_df)\n",
        "\n",
        "# Main script\n",
        "url = 'https://raw.githubusercontent.com/abhinavarorags/CoolStuff/refs/heads/test/sample_data.csv'\n",
        "train_data, test_data = load_data(url)\n",
        "q_table = train_q_learning(train_data)\n",
        "\n",
        "test_with_actions = test_q_learning(test_data, q_table)\n",
        "\n",
        "# Analyze the performance\n",
        "performanceAnalyse(test_with_actions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS3Pa2FG4fZ4",
        "outputId": "acd43077-1c40-400b-db12-53626281781e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 0, Alpha: 0.5000, Epsilon: 1.0000, Total Reward: 173.41\n",
            "After Episode 0: Q-Table Sample:\n",
            "[[ 0.3    0.     0.   ]\n",
            " [ 0.    -0.265  0.   ]\n",
            " [ 0.     0.    -0.16 ]\n",
            " [ 0.     0.     0.475]\n",
            " [ 0.     0.    -0.24 ]]\n",
            "Episode: 1, Alpha: 0.4975, Epsilon: 0.9950, Total Reward: 173.41\n",
            "After Episode 1: Q-Table Sample:\n",
            "[[ 0.44925     0.          0.        ]\n",
            " [ 0.         -0.265      -0.263675  ]\n",
            " [ 0.          0.         -0.01510312]\n",
            " [ 0.472625    0.          0.475     ]\n",
            " [ 0.          0.         -0.3594    ]]\n",
            "Episode: 2, Alpha: 0.4950, Epsilon: 0.9900, Total Reward: 173.41\n",
            "After Episode 2: Q-Table Sample:\n",
            "[[ 0.44925     0.2970075   0.        ]\n",
            " [-0.26235663 -0.265      -0.263675  ]\n",
            " [ 0.          0.06497039 -0.01510312]\n",
            " [ 0.472625    0.47026188  0.475     ]\n",
            " [ 0.         -0.237606   -0.3594    ]]\n",
            "Episode: 3, Alpha: 0.4925, Epsilon: 0.9851, Total Reward: 173.41\n",
            "After Episode 3: Q-Table Sample:\n",
            "[[ 0.44925     0.32348321  0.        ]\n",
            " [-0.36378067 -0.265      -0.263675  ]\n",
            " [ 0.06464554  0.06497039 -0.01510312]\n",
            " [ 0.70775006  0.47026188  0.475     ]\n",
            " [-0.28189229 -0.237606   -0.3594    ]]\n",
            "Episode: 4, Alpha: 0.4901, Epsilon: 0.9801, Total Reward: 173.41\n",
            "After Episode 4: Q-Table Sample:\n",
            "[[ 0.44925     0.32348321  0.17128541]\n",
            " [-0.41499224 -0.265      -0.263675  ]\n",
            " [ 0.06464554  0.06497039  0.16498253]\n",
            " [ 0.70775006  0.47026188  0.59716304]\n",
            " [-0.28189229 -0.237606   -0.46374996]]\n",
            "Episode: 5, Alpha: 0.4876, Epsilon: 0.9752, Total Reward: 173.41\n",
            "After Episode 5: Q-Table Sample:\n",
            "[[ 0.44925     0.32348321  0.25819146]\n",
            " [-0.3946458  -0.265      -0.263675  ]\n",
            " [ 0.06464554  0.06497039  0.2563536 ]\n",
            " [ 0.70775006  0.47026188  0.65914559]\n",
            " [-0.28189229 -0.40082393 -0.46374996]]\n",
            "Episode: 6, Alpha: 0.4852, Epsilon: 0.9704, Total Reward: 173.41\n",
            "After Episode 6: Q-Table Sample:\n",
            "[[ 0.44925     0.32348321  0.30249735]\n",
            " [-0.34215752 -0.265      -0.263675  ]\n",
            " [ 0.06464554  0.06497039  0.30293582]\n",
            " [ 0.70775006  0.57309247  0.65914559]\n",
            " [-0.28189229 -0.40082393 -0.50346543]]\n",
            "Episode: 7, Alpha: 0.4828, Epsilon: 0.9655, Total Reward: 173.41\n",
            "After Episode 7: Q-Table Sample:\n",
            "[[ 0.44925     0.33604731  0.30249735]\n",
            " [-0.34215752 -0.265      -0.25331302]\n",
            " [ 0.06464554  0.06497039  0.32679709]\n",
            " [ 0.70775006  0.62576638  0.65914559]\n",
            " [-0.28189229 -0.42859352 -0.50346543]]\n",
            "Episode: 8, Alpha: 0.4803, Epsilon: 0.9607, Total Reward: 173.41\n",
            "After Episode 8: Q-Table Sample:\n",
            "[[ 0.40606811  0.33604731  0.30249735]\n",
            " [-0.34215752 -0.24316478 -0.25331302]\n",
            " [ 0.06464554  0.20301822  0.32679709]\n",
            " [ 0.70775006  0.65287519  0.65914559]\n",
            " [-0.28189229 -0.40426516 -0.50346543]]\n",
            "Episode: 9, Alpha: 0.4779, Epsilon: 0.9559, Total Reward: 173.41\n",
            "After Episode 9: Q-Table Sample:\n",
            "[[ 0.38834848  0.33604731  0.30249735]\n",
            " [-0.28355444 -0.24316478 -0.25331302]\n",
            " [ 0.06464554  0.27439657  0.32679709]\n",
            " [ 0.70775006  0.66689194  0.65914559]\n",
            " [-0.28189229 -0.40426516 -0.40223373]]\n",
            "Episode: 10, Alpha: 0.4756, Epsilon: 0.9511, Total Reward: 173.41\n",
            "After Episode 10: Q-Table Sample:\n",
            "[[ 0.3791441   0.33604731  0.30249735]\n",
            " [-0.28355444 -0.23193121 -0.25331302]\n",
            " [ 0.06464554  0.27439657  0.33895488]\n",
            " [ 0.69560071  0.66689194  0.65914559]\n",
            " [-0.28653698 -0.40426516 -0.40223373]]\n",
            "Episode: 11, Alpha: 0.4732, Epsilon: 0.9464, Total Reward: 173.41\n",
            "After Episode 11: Q-Table Sample:\n",
            "[[ 0.3791441   0.35668638  0.30249735]\n",
            " [-0.28355444 -0.23193121 -0.23186855]\n",
            " [ 0.06464554  0.30582694  0.33895488]\n",
            " [ 0.69560071  0.66689194  0.66796764]\n",
            " [-0.23048193 -0.40426516 -0.40223373]]\n",
            "Episode: 12, Alpha: 0.4708, Epsilon: 0.9416, Total Reward: 173.41\n",
            "After Episode 12: Q-Table Sample:\n",
            "[[ 0.37941754  0.35668638  0.30249735]\n",
            " [-0.24797919 -0.23193121 -0.23186855]\n",
            " [ 0.06464554  0.32230239  0.33895488]\n",
            " [ 0.69560071  0.6970946   0.66796764]\n",
            " [-0.18969533 -0.40426516 -0.40223373]]\n",
            "Episode: 13, Alpha: 0.4685, Epsilon: 0.9369, Total Reward: 173.41\n",
            "After Episode 13: Q-Table Sample:\n",
            "[[ 0.37941754  0.36747893  0.30249735]\n",
            " [-0.24797919 -0.23193121 -0.22068381]\n",
            " [ 0.19468664  0.32230239  0.33895488]\n",
            " [ 0.69560071  0.73114903  0.66796764]\n",
            " [-0.18969533 -0.40426516 -0.28119267]]\n",
            "Episode: 14, Alpha: 0.4661, Epsilon: 0.9322, Total Reward: 173.41\n",
            "After Episode 14: Q-Table Sample:\n",
            "[[ 0.37941754  0.37813966  0.30249735]\n",
            " [-0.24797919 -0.23193121 -0.21476837]\n",
            " [ 0.19468664  0.32230239  0.35556568]\n",
            " [ 0.69560071  0.73114903  0.71542831]\n",
            " [-0.18969533 -0.22698547 -0.28119267]]\n",
            "Episode: 15, Alpha: 0.4638, Epsilon: 0.9276, Total Reward: 173.41\n",
            "After Episode 15: Q-Table Sample:\n",
            "[[ 0.38709433  0.37813966  0.30249735]\n",
            " [-0.24797919 -0.21351034 -0.21476837]\n",
            " [ 0.27812376  0.32230239  0.35556568]\n",
            " [ 0.69560071  0.73114903  0.74064016]\n",
            " [-0.18969533 -0.22698547 -0.13253465]]\n",
            "Episode: 16, Alpha: 0.4615, Epsilon: 0.9229, Total Reward: 173.41\n",
            "After Episode 16: Q-Table Sample:\n",
            "[[ 0.39174168  0.37813966  0.30249735]\n",
            " [-0.24797919 -0.21351034 -0.20435966]\n",
            " [ 0.27812376  0.32230239  0.36850631]\n",
            " [ 0.75489505  0.73114903  0.74064016]\n",
            " [-0.18969533 -0.05532076 -0.13253465]]\n",
            "Episode: 17, Alpha: 0.4592, Epsilon: 0.9183, Total Reward: 173.41\n",
            "After Episode 17: Q-Table Sample:\n",
            "[[ 0.39822345  0.37813966  0.30249735]\n",
            " [-0.21672879 -0.21351034 -0.20435966]\n",
            " [ 0.33277578  0.32230239  0.36850631]\n",
            " [ 0.75489505  0.73114903  0.81263852]\n",
            " [-0.18969533 -0.05532076 -0.00509613]]\n",
            "Episode: 18, Alpha: 0.4569, Epsilon: 0.9137, Total Reward: 173.41\n",
            "After Episode 18: Q-Table Sample:\n",
            "[[ 0.40171154  0.37813966  0.30249735]\n",
            " [-0.21672879 -0.21351034 -0.19319364]\n",
            " [ 0.38724786  0.32230239  0.36850631]\n",
            " [ 0.75489505  0.828922    0.81263852]\n",
            " [-0.18969533  0.10047946 -0.00509613]]\n",
            "Episode: 19, Alpha: 0.4546, Epsilon: 0.9092, Total Reward: 173.41\n",
            "After Episode 19: Q-Table Sample:\n",
            "[[ 0.40171154  0.37813966  0.35430503]\n",
            " [-0.21672879 -0.19014693 -0.19319364]\n",
            " [ 0.38724786  0.38829509  0.36850631]\n",
            " [ 0.88697747  0.828922    0.81263852]\n",
            " [-0.18969533  0.10047946  0.12709407]]\n",
            "Episode: 20, Alpha: 0.4523, Epsilon: 0.9046, Total Reward: 173.41\n",
            "After Episode 20: Q-Table Sample:\n",
            "[[ 0.40171154  0.37813966  0.38372992]\n",
            " [-0.21672879 -0.19014693 -0.17868641]\n",
            " [ 0.44848128  0.38829509  0.36850631]\n",
            " [ 0.88697747  0.93829726  0.81263852]\n",
            " [-0.18969533  0.10047946  0.26391413]]\n",
            "Episode: 21, Alpha: 0.4500, Epsilon: 0.9001, Total Reward: 173.41\n",
            "After Episode 21: Q-Table Sample:\n",
            "[[ 0.41455415  0.37813966  0.38372992]\n",
            " [-0.16597016 -0.19014693 -0.17868641]\n",
            " [ 0.44848128  0.38829509  0.45980942]\n",
            " [ 0.88697747  1.05639825  0.81263852]\n",
            " [ 0.0890097   0.10047946  0.26391413]]\n",
            "Episode: 22, Alpha: 0.4478, Epsilon: 0.8956, Total Reward: 173.41\n",
            "After Episode 22: Q-Table Sample:\n",
            "[[ 0.42699126  0.37813966  0.38372992]\n",
            " [-0.13337567 -0.19014693 -0.17868641]\n",
            " [ 0.44848128  0.38829509  0.56001169]\n",
            " [ 0.88697747  1.12102389  0.81263852]\n",
            " [ 0.0890097   0.29956717  0.26391413]]\n",
            "Episode: 23, Alpha: 0.4456, Epsilon: 0.8911, Total Reward: 173.41\n",
            "After Episode 23: Q-Table Sample:\n",
            "[[ 0.42699126  0.42053571  0.38372992]\n",
            " [-0.13337567 -0.10453005 -0.17868641]\n",
            " [ 0.44848128  0.38829509  0.6424219 ]\n",
            " [ 0.88697747  1.17162325  0.81263852]\n",
            " [ 0.0890097   0.29956717  0.38918734]]\n",
            "Episode: 24, Alpha: 0.4433, Epsilon: 0.8867, Total Reward: 173.41\n",
            "After Episode 24: Q-Table Sample:\n",
            "[[ 0.45966674  0.42053571  0.38372992]\n",
            " [-0.13337567 -0.10453005 -0.06387045]\n",
            " [ 0.6012343   0.38829509  0.6424219 ]\n",
            " [ 1.07882735  1.17162325  0.81263852]\n",
            " [ 0.0890097   0.29956717  0.46393947]]\n",
            "Episode: 25, Alpha: 0.4411, Epsilon: 0.8822, Total Reward: 173.41\n",
            "After Episode 25: Q-Table Sample:\n",
            "[[ 4.94803956e-01  4.20535710e-01  3.83729920e-01]\n",
            " [-1.33375671e-01 -1.04530048e-01 -2.75050425e-04]\n",
            " [ 6.85842659e-01  3.88295092e-01  6.42421900e-01]\n",
            " [ 1.21641628e+00  1.17162325e+00  8.12638521e-01]\n",
            " [ 8.90097037e-02  2.99567171e-01  5.30586181e-01]]\n",
            "Episode: 26, Alpha: 0.4389, Epsilon: 0.8778, Total Reward: 173.41\n",
            "After Episode 26: Q-Table Sample:\n",
            "[[ 0.5408603   0.42053571  0.38372992]\n",
            " [-0.13337567 -0.10453005  0.05319475]\n",
            " [ 0.68584266  0.38829509  0.72720666]\n",
            " [ 1.32071782  1.17162325  0.81263852]\n",
            " [ 0.0890097   0.29956717  0.6119095 ]]\n",
            "Episode: 27, Alpha: 0.4367, Epsilon: 0.8734, Total Reward: 173.41\n",
            "After Episode 27: Q-Table Sample:\n",
            "[[ 0.5408603   0.42053571  0.50024639]\n",
            " [-0.00488597 -0.10453005  0.05319475]\n",
            " [ 0.79451327  0.38829509  0.72720666]\n",
            " [ 1.4126873   1.17162325  0.81263852]\n",
            " [ 0.0890097   0.52664812  0.6119095 ]]\n",
            "Episode: 28, Alpha: 0.4345, Epsilon: 0.8691, Total Reward: 173.41\n",
            "After Episode 28: Q-Table Sample:\n",
            "[[ 0.58851687  0.42053571  0.50024639]\n",
            " [-0.00488597 -0.10453005  0.12775639]\n",
            " [ 0.79451327  0.66367967  0.72720666]\n",
            " [ 1.46423375  1.17162325  0.81263852]\n",
            " [ 0.0890097   0.52664812  0.70213402]]\n",
            "Episode: 29, Alpha: 0.4324, Epsilon: 0.8647, Total Reward: 173.41\n",
            "After Episode 29: Q-Table Sample:\n",
            "[[ 0.58851687  0.42053571  0.59584942]\n",
            " [-0.00488597 -0.10453005  0.16970821]\n",
            " [ 0.91406292  0.66367967  0.72720666]\n",
            " [ 1.53029464  1.17162325  0.81263852]\n",
            " [ 0.0890097   0.52664812  0.77718101]]\n",
            "Episode: 30, Alpha: 0.4302, Epsilon: 0.8604, Total Reward: 173.41\n",
            "After Episode 30: Q-Table Sample:\n",
            "[[ 0.58851687  0.42053571  0.66699174]\n",
            " [ 0.14277564 -0.10453005  0.16970821]\n",
            " [ 0.91406292  0.86591308  0.72720666]\n",
            " [ 1.59827675  1.17162325  0.81263852]\n",
            " [ 0.0890097   0.52664812  0.86968965]]\n",
            "Episode: 31, Alpha: 0.4280, Epsilon: 0.8561, Total Reward: 173.41\n",
            "After Episode 31: Q-Table Sample:\n",
            "[[0.58851687 0.42053571 0.70732651]\n",
            " [0.14277564 0.08504501 0.16970821]\n",
            " [0.91406292 1.00821528 0.72720666]\n",
            " [1.59827675 1.17162325 1.22508468]\n",
            " [0.0890097  0.52664812 0.92213824]]\n",
            "Episode: 32, Alpha: 0.4259, Epsilon: 0.8518, Total Reward: 173.41\n",
            "After Episode 32: Q-Table Sample:\n",
            "[[0.66207249 0.42053571 0.70732651]\n",
            " [0.2641697  0.08504501 0.16970821]\n",
            " [1.03514655 1.00821528 0.72720666]\n",
            " [1.69527764 1.17162325 1.22508468]\n",
            " [0.51350013 0.52664812 0.92213824]]\n",
            "Episode: 33, Alpha: 0.4238, Epsilon: 0.8475, Total Reward: 173.41\n",
            "After Episode 33: Q-Table Sample:\n",
            "[[0.66207249 0.42053571 0.76819479]\n",
            " [0.2641697  0.24113876 0.16970821]\n",
            " [1.03514655 1.12784531 0.72720666]\n",
            " [1.69527764 1.4489427  1.22508468]\n",
            " [0.51350013 0.52664812 0.99145015]]\n",
            "Episode: 34, Alpha: 0.4217, Epsilon: 0.8433, Total Reward: 173.41\n",
            "After Episode 34: Q-Table Sample:\n",
            "[[0.66207249 0.60202573 0.76819479]\n",
            " [0.2641697  0.36776705 0.16970821]\n",
            " [1.03514655 1.12784531 0.96472654]\n",
            " [1.77817453 1.4489427  1.22508468]\n",
            " [0.51350013 0.52664812 1.04721118]]\n",
            "Episode: 35, Alpha: 0.4195, Epsilon: 0.8391, Total Reward: 173.41\n",
            "After Episode 35: Q-Table Sample:\n",
            "[[0.78261017 0.60202573 0.76819479]\n",
            " [0.2641697  0.36776705 0.32567164]\n",
            " [1.03514655 1.2291319  0.96472654]\n",
            " [1.84810254 1.4489427  1.22508468]\n",
            " [0.51350013 0.52664812 1.10170476]]\n",
            "Episode: 36, Alpha: 0.4174, Epsilon: 0.8349, Total Reward: 173.41\n",
            "After Episode 36: Q-Table Sample:\n",
            "[[0.78261017 0.74702704 0.76819479]\n",
            " [0.42008834 0.36776705 0.32567164]\n",
            " [1.20235514 1.2291319  0.96472654]\n",
            " [1.84810254 1.67756852 1.22508468]\n",
            " [0.51350013 0.52664812 1.13317772]]\n",
            "Episode: 37, Alpha: 0.4154, Epsilon: 0.8307, Total Reward: 173.41\n",
            "After Episode 37: Q-Table Sample:\n",
            "[[0.78261017 0.74702704 0.86409675]\n",
            " [0.51046512 0.36776705 0.32567164]\n",
            " [1.20235514 1.31493082 0.96472654]\n",
            " [1.92220941 1.67756852 1.22508468]\n",
            " [0.51350013 0.79681886 1.13317772]]\n",
            "Episode: 38, Alpha: 0.4133, Epsilon: 0.8266, Total Reward: 173.41\n",
            "After Episode 38: Q-Table Sample:\n",
            "[[0.90755859 0.74702704 0.86409675]\n",
            " [0.51046512 0.36776705 0.48830355]\n",
            " [1.20235514 1.39393727 0.96472654]\n",
            " [1.92220941 1.67756852 1.55630344]\n",
            " [0.51350013 0.79681886 1.16765085]]\n",
            "Episode: 39, Alpha: 0.4112, Epsilon: 0.8224, Total Reward: 173.41\n",
            "After Episode 39: Q-Table Sample:\n",
            "[[0.98050145 0.74702704 0.86409675]\n",
            " [0.51046512 0.36776705 0.61410972]\n",
            " [1.20235514 1.44005996 0.96472654]\n",
            " [1.92220941 1.67756852 1.76313071]\n",
            " [0.83845088 0.79681886 1.16765085]]\n",
            "Episode: 40, Alpha: 0.4092, Epsilon: 0.8183, Total Reward: 173.41\n",
            "After Episode 40: Q-Table Sample:\n",
            "[[1.06352117 0.74702704 0.86409675]\n",
            " [0.51046512 0.36776705 0.70573999]\n",
            " [1.32663497 1.44005996 0.96472654]\n",
            " [1.97828844 1.67756852 1.76313071]\n",
            " [0.83845088 0.79681886 1.22412756]]\n",
            "Episode: 41, Alpha: 0.4071, Epsilon: 0.8142, Total Reward: 173.41\n",
            "After Episode 41: Q-Table Sample:\n",
            "[[1.06352117 0.74702704 1.02953017]\n",
            " [0.51046512 0.36776705 0.75960811]\n",
            " [1.42138635 1.44005996 0.96472654]\n",
            " [1.97828844 1.8548068  1.76313071]\n",
            " [0.83845088 0.79681886 1.25827436]]\n",
            "Episode: 42, Alpha: 0.4051, Epsilon: 0.8102, Total Reward: 173.41\n",
            "After Episode 42: Q-Table Sample:\n",
            "[[1.16807463 0.74702704 1.02953017]\n",
            " [0.51046512 0.36776705 0.79138607]\n",
            " [1.47728222 1.44005996 0.96472654]\n",
            " [1.97828844 1.8548068  1.91796391]\n",
            " [0.83845088 0.79681886 1.31935791]]\n",
            "Episode: 43, Alpha: 0.4031, Epsilon: 0.8061, Total Reward: 173.41\n",
            "After Episode 43: Q-Table Sample:\n",
            "[[1.16807463 0.74702704 1.15942885]\n",
            " [0.65675452 0.36776705 0.79138607]\n",
            " [1.47728222 1.44005996 1.20440117]\n",
            " [2.06901637 1.8548068  1.91796391]\n",
            " [0.83845088 1.05012938 1.31935791]]\n",
            "Episode: 44, Alpha: 0.4010, Epsilon: 0.8021, Total Reward: 173.41\n",
            "After Episode 44: Q-Table Sample:\n",
            "[[1.16807463 0.98957072 1.15942885]\n",
            " [0.74364486 0.36776705 0.79138607]\n",
            " [1.47728222 1.52247552 1.20440117]\n",
            " [2.06901637 1.8548068  2.03243063]\n",
            " [0.83845088 1.20457145 1.31935791]]\n",
            "Episode: 45, Alpha: 0.3990, Epsilon: 0.7981, Total Reward: 173.41\n",
            "After Episode 45: Q-Table Sample:\n",
            "[[1.24139377 0.98957072 1.15942885]\n",
            " [0.74364486 0.36776705 0.84125148]\n",
            " [1.47728222 1.57159248 1.20440117]\n",
            " [2.12263587 1.8548068  2.03243063]\n",
            " [0.83845088 1.20457145 1.39575214]]\n",
            "Episode: 46, Alpha: 0.3970, Epsilon: 0.7941, Total Reward: 173.41\n",
            "After Episode 46: Q-Table Sample:\n",
            "[[1.24139377 1.15220457 1.15942885]\n",
            " [0.74364486 0.36776705 0.88959533]\n",
            " [1.47728222 1.62118709 1.20440117]\n",
            " [2.18351312 1.8548068  2.03243063]\n",
            " [0.83845088 1.20457145 1.44143301]]\n",
            "Episode: 47, Alpha: 0.3951, Epsilon: 0.7901, Total Reward: 173.41\n",
            "After Episode 47: Q-Table Sample:\n",
            "[[1.32187457 1.15220457 1.15942885]\n",
            " [0.74364486 0.36776705 0.93721196]\n",
            " [1.47728222 1.62118709 1.42165487]\n",
            " [2.18351312 2.03833023 2.03243063]\n",
            " [1.12982435 1.20457145 1.44143301]]\n",
            "Episode: 48, Alpha: 0.3931, Epsilon: 0.7862, Total Reward: 173.41\n",
            "After Episode 48: Q-Table Sample:\n",
            "[[1.38809896 1.15220457 1.15942885]\n",
            " [0.74364486 0.6202644  0.93721196]\n",
            " [1.47728222 1.62118709 1.55242482]\n",
            " [2.18351312 2.14879717 2.03243063]\n",
            " [1.12982435 1.20457145 1.5097071 ]]\n",
            "Episode: 49, Alpha: 0.3911, Epsilon: 0.7822, Total Reward: 173.41\n",
            "After Episode 49: Q-Table Sample:\n",
            "[[1.42809109 1.15220457 1.15942885]\n",
            " [0.74364486 0.77274457 0.93721196]\n",
            " [1.47728222 1.67326378 1.55242482]\n",
            " [2.26201264 2.14879717 2.03243063]\n",
            " [1.12982435 1.20457145 1.55093702]]\n",
            "Episode: 50, Alpha: 0.3892, Epsilon: 0.7783, Total Reward: 173.41\n",
            "After Episode 50: Q-Table Sample:\n",
            "[[1.45232006 1.15220457 1.15942885]\n",
            " [0.86660101 0.77274457 0.93721196]\n",
            " [1.47728222 1.73383527 1.55242482]\n",
            " [2.26201264 2.25565676 2.03243063]\n",
            " [1.12982435 1.20457145 1.59248213]]\n",
            "Episode: 51, Alpha: 0.3872, Epsilon: 0.7744, Total Reward: 173.41\n",
            "After Episode 51: Q-Table Sample:\n",
            "[[1.45232006 1.15220457 1.28756552]\n",
            " [0.86660101 0.77274457 1.00688334]\n",
            " [1.47728222 1.77064998 1.55242482]\n",
            " [2.26201264 2.25565676 2.19909664]\n",
            " [1.12982435 1.39001158 1.59248213]]\n",
            "Episode: 52, Alpha: 0.3853, Epsilon: 0.7705, Total Reward: 173.41\n",
            "After Episode 52: Q-Table Sample:\n",
            "[[1.49247302 1.15220457 1.28756552]\n",
            " [0.97660321 0.77274457 1.00688334]\n",
            " [1.61275619 1.77064998 1.55242482]\n",
            " [2.26201264 2.25565676 2.30071716]\n",
            " [1.12982435 1.39001158 1.63358225]]\n",
            "Episode: 53, Alpha: 0.3833, Epsilon: 0.7667, Total Reward: 173.41\n",
            "After Episode 53: Q-Table Sample:\n",
            "[[1.49247302 1.30720546 1.28756552]\n",
            " [0.97660321 0.77274457 1.06255857]\n",
            " [1.61275619 1.80708005 1.55242482]\n",
            " [2.26201264 2.25565676 2.37784141]\n",
            " [1.34807793 1.39001158 1.63358225]]\n",
            "Episode: 54, Alpha: 0.3814, Epsilon: 0.7629, Total Reward: 173.41\n",
            "After Episode 54: Q-Table Sample:\n",
            "[[1.49247302 1.30720546 1.41033496]\n",
            " [0.97660321 0.93065008 1.06255857]\n",
            " [1.61275619 1.85737913 1.55242482]\n",
            " [2.26201264 2.34958284 2.37784141]\n",
            " [1.34807793 1.39001158 1.65859551]]\n",
            "Episode: 55, Alpha: 0.3795, Epsilon: 0.7590, Total Reward: 173.41\n",
            "After Episode 55: Q-Table Sample:\n",
            "[[1.53686127 1.30720546 1.41033496]\n",
            " [0.97660321 0.93065008 1.12781836]\n",
            " [1.73655438 1.85737913 1.55242482]\n",
            " [2.26201264 2.34958284 2.43394432]\n",
            " [1.48132192 1.39001158 1.65859551]]\n",
            "Episode: 56, Alpha: 0.3776, Epsilon: 0.7553, Total Reward: 173.41\n",
            "After Episode 56: Q-Table Sample:\n",
            "[[1.53686127 1.30720546 1.50893041]\n",
            " [1.07399573 0.93065008 1.12781836]\n",
            " [1.73655438 1.90830886 1.55242482]\n",
            " [2.26201264 2.34958284 2.46858076]\n",
            " [1.48132192 1.39001158 1.69466679]]\n",
            "Episode: 57, Alpha: 0.3757, Epsilon: 0.7515, Total Reward: 173.41\n",
            "After Episode 57: Q-Table Sample:\n",
            "[[1.58742295 1.30720546 1.50893041]\n",
            " [1.15248662 0.93065008 1.12781836]\n",
            " [1.73655438 1.95221121 1.55242482]\n",
            " [2.26201264 2.42861965 2.46858076]\n",
            " [1.48132192 1.39001158 1.71997131]]\n",
            "Episode: 58, Alpha: 0.3739, Epsilon: 0.7477, Total Reward: 173.41\n",
            "After Episode 58: Q-Table Sample:\n",
            "[[1.58742295 1.45213474 1.50893041]\n",
            " [1.21683312 0.93065008 1.12781836]\n",
            " [1.73655438 1.95221121 1.72915837]\n",
            " [2.26201264 2.42861965 2.51172118]\n",
            " [1.48132192 1.39001158 1.75274155]]\n",
            "Episode: 59, Alpha: 0.3720, Epsilon: 0.7440, Total Reward: 173.41\n",
            "After Episode 59: Q-Table Sample:\n",
            "[[1.65012883 1.45213474 1.50893041]\n",
            " [1.21683312 0.93065008 1.20101949]\n",
            " [1.73655438 1.99458982 1.72915837]\n",
            " [2.26201264 2.42861965 2.55017877]\n",
            " [1.48132192 1.39001158 1.77315772]]\n",
            "Episode: 60, Alpha: 0.3701, Epsilon: 0.7403, Total Reward: 173.41\n",
            "After Episode 60: Q-Table Sample:\n",
            "[[1.65012883 1.56460137 1.50893041]\n",
            " [1.2716225  0.93065008 1.20101949]\n",
            " [1.73655438 2.03459353 1.72915837]\n",
            " [2.39988151 2.42861965 2.55017877]\n",
            " [1.48132192 1.39001158 1.80391845]]\n",
            "Episode: 61, Alpha: 0.3683, Epsilon: 0.7366, Total Reward: 173.41\n",
            "After Episode 61: Q-Table Sample:\n",
            "[[1.65012883 1.56460137 1.61908695]\n",
            " [1.31995604 0.93065008 1.20101949]\n",
            " [1.73655438 2.05966466 1.72915837]\n",
            " [2.39988151 2.51520329 2.55017877]\n",
            " [1.48132192 1.57291696 1.80391845]]\n",
            "Episode: 62, Alpha: 0.3664, Epsilon: 0.7329, Total Reward: 173.41\n",
            "After Episode 62: Q-Table Sample:\n",
            "[[1.72481976 1.56460137 1.61908695]\n",
            " [1.35906432 0.93065008 1.20101949]\n",
            " [1.73655438 2.07542341 1.72915837]\n",
            " [2.39988151 2.51520329 2.59178557]\n",
            " [1.48132192 1.68788425 1.80391845]]\n",
            "Episode: 63, Alpha: 0.3646, Epsilon: 0.7292, Total Reward: 173.41\n",
            "After Episode 63: Q-Table Sample:\n",
            "[[1.78545062 1.56460137 1.61908695]\n",
            " [1.35906432 0.93065008 1.28875569]\n",
            " [1.88445395 2.07542341 1.72915837]\n",
            " [2.39988151 2.51520329 2.61801423]\n",
            " [1.63806543 1.68788425 1.80391845]]\n",
            "Episode: 64, Alpha: 0.3628, Epsilon: 0.7256, Total Reward: 173.41\n",
            "After Episode 64: Q-Table Sample:\n",
            "[[1.78545062 1.56460137 1.71777274]\n",
            " [1.38902583 0.93065008 1.28875569]\n",
            " [1.88445395 2.10868704 1.72915837]\n",
            " [2.4955986  2.51520329 2.61801423]\n",
            " [1.63806543 1.68788425 1.84284564]]\n",
            "Episode: 65, Alpha: 0.3610, Epsilon: 0.7219, Total Reward: 173.41\n",
            "After Episode 65: Q-Table Sample:\n",
            "[[1.83386524 1.56460137 1.71777274]\n",
            " [1.38902583 0.93065008 1.35535344]\n",
            " [1.88445395 2.1297772  1.72915837]\n",
            " [2.56963511 2.51520329 2.61801423]\n",
            " [1.74464407 1.68788425 1.84284564]]\n",
            "Episode: 66, Alpha: 0.3592, Epsilon: 0.7183, Total Reward: 173.41\n",
            "After Episode 66: Q-Table Sample:\n",
            "[[1.86464897 1.56460137 1.71777274]\n",
            " [1.42647322 0.93065008 1.35535344]\n",
            " [1.98597522 2.1297772  1.72915837]\n",
            " [2.61671017 2.51520329 2.61801423]\n",
            " [1.74464407 1.68788425 1.87534161]]\n",
            "Episode: 67, Alpha: 0.3574, Epsilon: 0.7147, Total Reward: 173.41\n",
            "After Episode 67: Q-Table Sample:\n",
            "[[1.89699104 1.56460137 1.71777274]\n",
            " [1.45035085 0.93065008 1.35535344]\n",
            " [1.98597522 2.14312003 1.72915837]\n",
            " [2.65775909 2.51520329 2.61801423]\n",
            " [1.74464407 1.68788425 1.90344003]]\n",
            "Episode: 68, Alpha: 0.3556, Epsilon: 0.7112, Total Reward: 173.41\n",
            "After Episode 68: Q-Table Sample:\n",
            "[[1.89699104 1.71153912 1.71777274]\n",
            " [1.45035085 1.13522123 1.35535344]\n",
            " [1.98597522 2.1650776  1.72915837]\n",
            " [2.65775909 2.60163268 2.61801423]\n",
            " [1.74464407 1.68788425 1.92608756]]\n",
            "Episode: 69, Alpha: 0.3538, Epsilon: 0.7076, Total Reward: 173.41\n",
            "After Episode 69: Q-Table Sample:\n",
            "[[1.89699104 1.71153912 1.80978318]\n",
            " [1.47740725 1.13522123 1.35535344]\n",
            " [1.98597522 2.1791567  1.72915837]\n",
            " [2.70093168 2.60163268 2.61801423]\n",
            " [1.74464407 1.68788425 1.94060906]]\n",
            "Episode: 70, Alpha: 0.3520, Epsilon: 0.7041, Total Reward: 173.41\n",
            "After Episode 70: Q-Table Sample:\n",
            "[[1.89699104 1.81433251 1.80978318]\n",
            " [1.47740725 1.27778747 1.35535344]\n",
            " [1.98597522 2.20264742 1.72915837]\n",
            " [2.73354663 2.60163268 2.61801423]\n",
            " [1.74464407 1.68788425 1.95731115]]\n",
            "Episode: 71, Alpha: 0.3503, Epsilon: 0.7005, Total Reward: 173.41\n",
            "After Episode 71: Q-Table Sample:\n",
            "[[1.89699104 1.88060601 1.80978318]\n",
            " [1.50721835 1.27778747 1.35535344]\n",
            " [1.98597522 2.20264742 1.92100764]\n",
            " [2.73354663 2.67442428 2.61801423]\n",
            " [1.83641435 1.68788425 1.95731115]]\n",
            "Episode: 72, Alpha: 0.3485, Epsilon: 0.6970, Total Reward: 173.41\n",
            "After Episode 72: Q-Table Sample:\n",
            "[[1.89699104 1.93332066 1.80978318]\n",
            " [1.50721835 1.37702167 1.35535344]\n",
            " [1.98597522 2.22851548 1.92100764]\n",
            " [2.73354663 2.72148235 2.61801423]\n",
            " [1.83641435 1.68788425 1.97450315]]\n",
            "Episode: 73, Alpha: 0.3468, Epsilon: 0.6936, Total Reward: 173.41\n",
            "After Episode 73: Q-Table Sample:\n",
            "[[1.89699104 1.96749131 1.80978318]\n",
            " [1.5349162  1.37702167 1.35535344]\n",
            " [2.08685166 2.22851548 1.92100764]\n",
            " [2.76553068 2.72148235 2.61801423]\n",
            " [1.83641435 1.68788425 1.98564733]]\n",
            "Episode: 74, Alpha: 0.3450, Epsilon: 0.6901, Total Reward: 173.41\n",
            "After Episode 74: Q-Table Sample:\n",
            "[[1.95260545 1.96749131 1.80978318]\n",
            " [1.5529185  1.37702167 1.35535344]\n",
            " [2.08685166 2.22851548 2.05428075]\n",
            " [2.78997182 2.72148235 2.61801423]\n",
            " [1.83641435 1.80380827 1.98564733]]\n",
            "Episode: 75, Alpha: 0.3433, Epsilon: 0.6866, Total Reward: 173.41\n",
            "After Episode 75: Q-Table Sample:\n",
            "[[1.99471972 1.96749131 1.80978318]\n",
            " [1.56465021 1.37702167 1.35535344]\n",
            " [2.08685166 2.22851548 2.14910358]\n",
            " [2.78997182 2.72148235 2.69297874]\n",
            " [1.83641435 1.80380827 2.00366156]]\n",
            "Episode: 76, Alpha: 0.3416, Epsilon: 0.6832, Total Reward: 173.41\n",
            "After Episode 76: Q-Table Sample:\n",
            "[[2.0260442  1.96749131 1.80978318]\n",
            " [1.56465021 1.44878195 1.35535344]\n",
            " [2.170074   2.22851548 2.14910358]\n",
            " [2.81166601 2.72148235 2.69297874]\n",
            " [1.90531724 1.80380827 2.00366156]]\n",
            "Episode: 77, Alpha: 0.3399, Epsilon: 0.6798, Total Reward: 173.41\n",
            "After Episode 77: Q-Table Sample:\n",
            "[[2.04656497 1.96749131 1.80978318]\n",
            " [1.56465021 1.44878195 1.43411988]\n",
            " [2.2315983  2.22851548 2.14910358]\n",
            " [2.81166601 2.76634743 2.69297874]\n",
            " [1.90531724 1.88726769 2.00366156]]\n",
            "Episode: 78, Alpha: 0.3382, Epsilon: 0.6764, Total Reward: 173.41\n",
            "After Episode 78: Q-Table Sample:\n",
            "[[2.04656497 2.00771191 1.80978318]\n",
            " [1.56465021 1.49654775 1.43411988]\n",
            " [2.2315983  2.22851548 2.21741241]\n",
            " [2.81166601 2.79581493 2.69297874]\n",
            " [1.90531724 1.94208405 2.00366156]]\n",
            "Episode: 79, Alpha: 0.3365, Epsilon: 0.6730, Total Reward: 173.41\n",
            "After Episode 79: Q-Table Sample:\n",
            "[[2.04656497 2.03419691 1.80978318]\n",
            " [1.56465021 1.52800122 1.43411988]\n",
            " [2.2315983  2.26976014 2.21741241]\n",
            " [2.82573618 2.79581493 2.69297874]\n",
            " [1.90531724 1.97818027 2.00366156]]\n",
            "Episode: 80, Alpha: 0.3348, Epsilon: 0.6696, Total Reward: 173.41\n",
            "After Episode 80: Q-Table Sample:\n",
            "[[2.05990861 2.03419691 1.80978318]\n",
            " [1.56465021 1.56090467 1.43411988]\n",
            " [2.2315983  2.30146436 2.21741241]\n",
            " [2.82573618 2.79581493 2.74671789]\n",
            " [1.90531724 1.97818027 2.02228785]]\n",
            "Episode: 81, Alpha: 0.3331, Epsilon: 0.6663, Total Reward: 173.41\n",
            "After Episode 81: Q-Table Sample:\n",
            "[[2.06874011 2.03419691 1.80978318]\n",
            " [1.56465021 1.56090467 1.5081695 ]\n",
            " [2.2315983  2.3224478  2.21741241]\n",
            " [2.82573618 2.82092061 2.74671789]\n",
            " [1.90531724 1.97818027 2.03680185]]\n",
            "Episode: 82, Alpha: 0.3315, Epsilon: 0.6630, Total Reward: 173.41\n",
            "After Episode 82: Q-Table Sample:\n",
            "[[2.06874011 2.03419691 1.90148311]\n",
            " [1.60166876 1.56090467 1.5081695 ]\n",
            " [2.2315983  2.3224478  2.26615281]\n",
            " [2.84536851 2.82092061 2.74671789]\n",
            " [1.90531724 2.00724266 2.03680185]]\n",
            "Episode: 83, Alpha: 0.3298, Epsilon: 0.6597, Total Reward: 173.41\n",
            "After Episode 83: Q-Table Sample:\n",
            "[[2.08616987 2.03419691 1.90148311]\n",
            " [1.60166876 1.56090467 1.5636318 ]\n",
            " [2.2315983  2.3224478  2.30472514]\n",
            " [2.84536851 2.82092061 2.7923144 ]\n",
            " [1.90531724 2.00724266 2.04638397]]\n",
            "Episode: 84, Alpha: 0.3282, Epsilon: 0.6564, Total Reward: 173.41\n",
            "After Episode 84: Q-Table Sample:\n",
            "[[2.09779242 2.03419691 1.90148311]\n",
            " [1.60166876 1.56090467 1.60061531]\n",
            " [2.28131778 2.3224478  2.30472514]\n",
            " [2.86134953 2.82092061 2.7923144 ]\n",
            " [1.90531724 2.00724266 2.05540782]]\n",
            "Episode: 85, Alpha: 0.3265, Epsilon: 0.6531, Total Reward: 173.41\n",
            "After Episode 85: Q-Table Sample:\n",
            "[[2.10556167 2.03419691 1.90148311]\n",
            " [1.62604689 1.56090467 1.60061531]\n",
            " [2.28131778 2.3224478  2.33527489]\n",
            " [2.86134953 2.82092061 2.82833891]\n",
            " [1.90531724 2.03153747 2.05540782]]\n",
            "Episode: 86, Alpha: 0.3249, Epsilon: 0.6498, Total Reward: 173.41\n",
            "After Episode 86: Q-Table Sample:\n",
            "[[2.11829234 2.03419691 1.90148311]\n",
            " [1.64634177 1.56090467 1.60061531]\n",
            " [2.28131778 2.3224478  2.35574617]\n",
            " [2.87476413 2.82092061 2.82833891]\n",
            " [1.90531724 2.03153747 2.06645818]]\n",
            "Episode: 87, Alpha: 0.3233, Epsilon: 0.6466, Total Reward: 173.41\n",
            "After Episode 87: Q-Table Sample:\n",
            "[[2.11829234 2.07616756 1.90148311]\n",
            " [1.64634177 1.60844426 1.60061531]\n",
            " [2.28131778 2.3224478  2.37361697]\n",
            " [2.88716873 2.82092061 2.82833891]\n",
            " [1.90531724 2.05024938 2.06645818]]\n",
            "Episode: 88, Alpha: 0.3217, Epsilon: 0.6433, Total Reward: 173.41\n",
            "After Episode 88: Q-Table Sample:\n",
            "[[2.13300274 2.07616756 1.90148311]\n",
            " [1.64634177 1.60844426 1.64060471]\n",
            " [2.28131778 2.3224478  2.38944064]\n",
            " [2.89552121 2.82092061 2.82833891]\n",
            " [1.90531724 2.05024938 2.0765714 ]]\n",
            "Episode: 89, Alpha: 0.3201, Epsilon: 0.6401, Total Reward: 173.41\n",
            "After Episode 89: Q-Table Sample:\n",
            "[[2.14293146 2.07616756 1.90148311]\n",
            " [1.67630748 1.60844426 1.64060471]\n",
            " [2.28131778 2.3224478  2.40266034]\n",
            " [2.89552121 2.82092061 2.85855333]\n",
            " [1.9687812  2.05024938 2.0765714 ]]\n",
            "Episode: 90, Alpha: 0.3185, Epsilon: 0.6369, Total Reward: 173.41\n",
            "After Episode 90: Q-Table Sample:\n",
            "[[2.14293146 2.07616756 1.99415621]\n",
            " [1.67630748 1.65432815 1.64060471]\n",
            " [2.28131778 2.3224478  2.41160407]\n",
            " [2.90419005 2.82092061 2.85855333]\n",
            " [1.9687812  2.05024938 2.08677162]]\n",
            "Episode: 91, Alpha: 0.3169, Epsilon: 0.6337, Total Reward: 173.41\n",
            "After Episode 91: Q-Table Sample:\n",
            "[[2.15863535 2.07616756 1.99415621]\n",
            " [1.7031509  1.65432815 1.64060471]\n",
            " [2.28131778 2.3224478  2.42027864]\n",
            " [2.90419005 2.85625468 2.85855333]\n",
            " [1.9687812  2.05024938 2.09368878]]\n",
            "Episode: 92, Alpha: 0.3153, Epsilon: 0.6306, Total Reward: 173.41\n",
            "After Episode 92: Q-Table Sample:\n",
            "[[2.17734961 2.07616756 1.99415621]\n",
            " [1.72399512 1.65432815 1.64060471]\n",
            " [2.28131778 2.35918799 2.42027864]\n",
            " [2.90419005 2.88234381 2.85855333]\n",
            " [1.9687812  2.05024938 2.0999342 ]]\n",
            "Episode: 93, Alpha: 0.3137, Epsilon: 0.6274, Total Reward: 173.41\n",
            "After Episode 93: Q-Table Sample:\n",
            "[[2.17734961 2.12687043 1.99415621]\n",
            " [1.72399512 1.65432815 1.68096554]\n",
            " [2.28131778 2.38421903 2.42027864]\n",
            " [2.90419005 2.90197954 2.85855333]\n",
            " [2.01542193 2.05024938 2.0999342 ]]\n",
            "Episode: 94, Alpha: 0.3121, Epsilon: 0.6243, Total Reward: 173.41\n",
            "After Episode 94: Q-Table Sample:\n",
            "[[2.17734961 2.12687043 2.07020401]\n",
            " [1.73812525 1.65432815 1.68096554]\n",
            " [2.28131778 2.38421903 2.42611612]\n",
            " [2.91690867 2.90197954 2.85855333]\n",
            " [2.01542193 2.05024938 2.10540455]]\n",
            "Episode: 95, Alpha: 0.3106, Epsilon: 0.6211, Total Reward: 173.41\n",
            "After Episode 95: Q-Table Sample:\n",
            "[[2.20029139 2.12687043 2.07020401]\n",
            " [1.74951861 1.65432815 1.68096554]\n",
            " [2.28131778 2.38421903 2.433864  ]\n",
            " [2.91690867 2.91693508 2.85855333]\n",
            " [2.01542193 2.07208968 2.10540455]]\n",
            "Episode: 96, Alpha: 0.3090, Epsilon: 0.6180, Total Reward: 173.41\n",
            "After Episode 96: Q-Table Sample:\n",
            "[[2.20029139 2.12687043 2.12948588]\n",
            " [1.74951861 1.65432815 1.71223993]\n",
            " [2.28131778 2.38421903 2.43918665]\n",
            " [2.91690867 2.92719429 2.85855333]\n",
            " [2.01542193 2.07208968 2.11113695]]\n",
            "Episode: 97, Alpha: 0.3075, Epsilon: 0.6149, Total Reward: 173.41\n",
            "After Episode 97: Q-Table Sample:\n",
            "[[2.21927833 2.12687043 2.12948588]\n",
            " [1.76111307 1.65432815 1.71223993]\n",
            " [2.28131778 2.38421903 2.44584283]\n",
            " [2.92879914 2.92719429 2.85855333]\n",
            " [2.01542193 2.07208968 2.11507812]]\n",
            "Episode: 98, Alpha: 0.3059, Epsilon: 0.6119, Total Reward: 173.41\n",
            "After Episode 98: Q-Table Sample:\n",
            "[[2.21927833 2.12687043 2.17340972]\n",
            " [1.77103694 1.65432815 1.71223993]\n",
            " [2.28131778 2.38421903 2.4508958 ]\n",
            " [2.93813789 2.92719429 2.85855333]\n",
            " [2.01542193 2.07208968 2.11779384]]\n",
            "Episode: 99, Alpha: 0.3044, Epsilon: 0.6088, Total Reward: 173.41\n",
            "After Episode 99: Q-Table Sample:\n",
            "[[2.23851892 2.12687043 2.17340972]\n",
            " [1.77935154 1.65432815 1.71223993]\n",
            " [2.28131778 2.38421903 2.45708598]\n",
            " [2.94537251 2.92719429 2.85855333]\n",
            " [2.04978915 2.07208968 2.11779384]]\n",
            "Episode: 100, Alpha: 0.3029, Epsilon: 0.6058, Total Reward: 173.41\n",
            "After Episode 100: Q-Table Sample:\n",
            "[[2.25422808 2.12687043 2.17340972]\n",
            " [1.78688737 1.65432815 1.71223993]\n",
            " [2.28131778 2.38421903 2.46345199]\n",
            " [2.9503797  2.92719429 2.85855333]\n",
            " [2.07357521 2.07208968 2.11779384]]\n",
            "Episode: 101, Alpha: 0.3014, Epsilon: 0.6027, Total Reward: 173.41\n",
            "After Episode 101: Q-Table Sample:\n",
            "[[2.26728193 2.12687043 2.17340972]\n",
            " [1.79393704 1.65432815 1.71223993]\n",
            " [2.34205693 2.38421903 2.46345199]\n",
            " [2.95385283 2.92719429 2.85855333]\n",
            " [2.09131236 2.07208968 2.11779384]]\n",
            "Episode: 102, Alpha: 0.2999, Epsilon: 0.5997, Total Reward: 173.41\n",
            "After Episode 102: Q-Table Sample:\n",
            "[[2.26728193 2.12687043 2.21264106]\n",
            " [1.79883752 1.65432815 1.71223993]\n",
            " [2.34205693 2.38421903 2.47026136]\n",
            " [2.95385283 2.92719429 2.88954451]\n",
            " [2.09131236 2.07208968 2.12218273]]\n",
            "Episode: 103, Alpha: 0.2984, Epsilon: 0.5967, Total Reward: 173.41\n",
            "After Episode 103: Q-Table Sample:\n",
            "[[2.26728193 2.18118031 2.21264106]\n",
            " [1.80418146 1.65432815 1.71223993]\n",
            " [2.38505224 2.38421903 2.47026136]\n",
            " [2.95385283 2.9387945  2.88954451]\n",
            " [2.09131236 2.09009313 2.12218273]]\n",
            "Episode: 104, Alpha: 0.2969, Epsilon: 0.5937, Total Reward: 173.41\n",
            "After Episode 104: Q-Table Sample:\n",
            "[[2.28114306 2.18118031 2.21264106]\n",
            " [1.80791221 1.65432815 1.71223993]\n",
            " [2.38505224 2.38421903 2.47498129]\n",
            " [2.95385283 2.9387945  2.91226391]\n",
            " [2.09131236 2.09009313 2.12679553]]\n",
            "Episode: 105, Alpha: 0.2954, Epsilon: 0.5908, Total Reward: 173.41\n",
            "After Episode 105: Q-Table Sample:\n",
            "[[2.29188738 2.18118031 2.21264106]\n",
            " [1.81184679 1.65432815 1.71223993]\n",
            " [2.38505224 2.41433127 2.47498129]\n",
            " [2.95385283 2.94814687 2.91226391]\n",
            " [2.10502084 2.09009313 2.12679553]]\n",
            "Episode: 106, Alpha: 0.2939, Epsilon: 0.5878, Total Reward: 173.41\n",
            "After Episode 106: Q-Table Sample:\n",
            "[[2.3005187  2.18118031 2.21264106]\n",
            " [1.81460528 1.65432815 1.71223993]\n",
            " [2.38505224 2.41433127 2.4782669 ]\n",
            " [2.95873262 2.94814687 2.91226391]\n",
            " [2.10502084 2.10409142 2.12679553]]\n",
            "Episode: 107, Alpha: 0.2924, Epsilon: 0.5849, Total Reward: 173.41\n",
            "After Episode 107: Q-Table Sample:\n",
            "[[2.30734907 2.18118031 2.21264106]\n",
            " [1.81460528 1.70405071 1.71223993]\n",
            " [2.38505224 2.41433127 2.48193093]\n",
            " [2.96216095 2.94814687 2.91226391]\n",
            " [2.10502084 2.10409142 2.13270335]]\n",
            "Episode: 108, Alpha: 0.2910, Epsilon: 0.5820, Total Reward: 173.41\n",
            "After Episode 108: Q-Table Sample:\n",
            "[[2.30734907 2.18118031 2.24500788]\n",
            " [1.81845468 1.70405071 1.71223993]\n",
            " [2.38505224 2.41433127 2.48545818]\n",
            " [2.96620768 2.94814687 2.91226391]\n",
            " [2.10502084 2.11657614 2.13270335]]\n",
            "Episode: 109, Alpha: 0.2895, Epsilon: 0.5790, Total Reward: 173.41\n",
            "After Episode 109: Q-Table Sample:\n",
            "[[2.31319251 2.18118031 2.24500788]\n",
            " [1.8221405  1.70405071 1.71223993]\n",
            " [2.38505224 2.41433127 2.48905961]\n",
            " [2.96620768 2.95623078 2.91226391]\n",
            " [2.10502084 2.11657614 2.13970877]]\n",
            "Episode: 110, Alpha: 0.2881, Epsilon: 0.5762, Total Reward: 173.41\n",
            "After Episode 110: Q-Table Sample:\n",
            "[[2.31833209 2.18118031 2.24500788]\n",
            " [1.8221405  1.74166089 1.71223993]\n",
            " [2.38505224 2.43840474 2.48905961]\n",
            " [2.97096546 2.95623078 2.91226391]\n",
            " [2.10502084 2.11657614 2.1475751 ]]\n",
            "Episode: 111, Alpha: 0.2866, Epsilon: 0.5733, Total Reward: 173.41\n",
            "After Episode 111: Q-Table Sample:\n",
            "[[2.32197277 2.18118031 2.24500788]\n",
            " [1.8221405  1.74166089 1.74731473]\n",
            " [2.38505224 2.43840474 2.49288838]\n",
            " [2.97647774 2.95623078 2.91226391]\n",
            " [2.10502084 2.11657614 2.15606935]]\n",
            "Episode: 112, Alpha: 0.2852, Epsilon: 0.5704, Total Reward: 173.41\n",
            "After Episode 112: Q-Table Sample:\n",
            "[[2.32197277 2.22391898 2.24500788]\n",
            " [1.82673327 1.74166089 1.74731473]\n",
            " [2.42001867 2.43840474 2.49288838]\n",
            " [2.97647774 2.95623078 2.93679199]\n",
            " [2.12560926 2.11657614 2.15606935]]\n",
            "Episode: 113, Alpha: 0.2838, Epsilon: 0.5676, Total Reward: 173.41\n",
            "After Episode 113: Q-Table Sample:\n",
            "[[2.32578215 2.22391898 2.24500788]\n",
            " [1.82999974 1.74166089 1.74731473]\n",
            " [2.44488757 2.43840474 2.49288838]\n",
            " [2.98266073 2.95623078 2.93679199]\n",
            " [2.12560926 2.1366941  2.15606935]]\n",
            "Episode: 114, Alpha: 0.2824, Epsilon: 0.5647, Total Reward: 173.41\n",
            "After Episode 114: Q-Table Sample:\n",
            "[[2.32937308 2.22391898 2.24500788]\n",
            " [1.82999974 1.74166089 1.77298939]\n",
            " [2.44488757 2.43840474 2.49871607]\n",
            " [2.98266073 2.95623078 2.95414968]\n",
            " [2.12560926 2.1366941  2.16699593]]\n",
            "Episode: 115, Alpha: 0.2809, Epsilon: 0.5619, Total Reward: 173.41\n",
            "After Episode 115: Q-Table Sample:\n",
            "[[2.33193719 2.22391898 2.24500788]\n",
            " [1.83387134 1.74166089 1.77298939]\n",
            " [2.44488757 2.43840474 2.50287735]\n",
            " [2.98266073 2.97095671 2.95414968]\n",
            " [2.12560926 2.15300947 2.16699593]]\n",
            "Episode: 116, Alpha: 0.2795, Epsilon: 0.5591, Total Reward: 173.41\n",
            "After Episode 116: Q-Table Sample:\n",
            "[[2.33479987 2.22391898 2.24500788]\n",
            " [1.83387134 1.77131266 1.77298939]\n",
            " [2.44488757 2.43840474 2.50585457]\n",
            " [2.98266073 2.97095671 2.96938374]\n",
            " [2.12560926 2.15300947 2.17620554]]\n",
            "Episode: 117, Alpha: 0.2781, Epsilon: 0.5563, Total Reward: 173.41\n",
            "After Episode 117: Q-Table Sample:\n",
            "[[2.33685199 2.22391898 2.24500788]\n",
            " [1.83387134 1.79335538 1.77298939]\n",
            " [2.44488757 2.43840474 2.50798881]\n",
            " [2.99232195 2.97095671 2.96938374]\n",
            " [2.12560926 2.15300947 2.18383719]]\n",
            "Episode: 118, Alpha: 0.2768, Epsilon: 0.5535, Total Reward: 173.41\n",
            "After Episode 118: Q-Table Sample:\n",
            "[[2.33685199 2.22391898 2.27190002]\n",
            " [1.83905162 1.79335538 1.77298939]\n",
            " [2.44488757 2.43840474 2.5120618 ]\n",
            " [2.99232195 2.98581524 2.96938374]\n",
            " [2.14929499 2.15300947 2.18383719]]\n",
            "Episode: 119, Alpha: 0.2754, Epsilon: 0.5507, Total Reward: 173.41\n",
            "After Episode 119: Q-Table Sample:\n",
            "[[2.33685199 2.22391898 2.29260757]\n",
            " [1.84384501 1.79335538 1.77298939]\n",
            " [2.44488757 2.46161873 2.5120618 ]\n",
            " [2.99232195 2.99650788 2.96938374]\n",
            " [2.14929499 2.15300947 2.19286357]]\n",
            "Episode: 120, Alpha: 0.2740, Epsilon: 0.5480, Total Reward: 173.41\n",
            "After Episode 120: Q-Table Sample:\n",
            "[[2.3409073  2.22391898 2.29260757]\n",
            " [1.84730108 1.79335538 1.77298939]\n",
            " [2.44488757 2.46161873 2.51606777]\n",
            " [2.99232195 3.00656686 2.96938374]\n",
            " [2.14929499 2.15300947 2.20044089]]\n",
            "Episode: 121, Alpha: 0.2726, Epsilon: 0.5452, Total Reward: 173.41\n",
            "After Episode 121: Q-Table Sample:\n",
            "[[2.34473186 2.22391898 2.29260757]\n",
            " [1.84730108 1.79335538 1.79678258]\n",
            " [2.44488757 2.46161873 2.52156678]\n",
            " [3.00543428 3.00656686 2.96938374]\n",
            " [2.14929499 2.17321043 2.20044089]]\n",
            "Episode: 122, Alpha: 0.2713, Epsilon: 0.5425, Total Reward: 173.41\n",
            "After Episode 122: Q-Table Sample:\n",
            "[[2.34749984 2.22391898 2.29260757]\n",
            " [1.85223459 1.79335538 1.79678258]\n",
            " [2.46966743 2.46161873 2.52156678]\n",
            " [3.00543428 3.01574955 2.96938374]\n",
            " [2.14929499 2.17321043 2.2076746 ]]\n",
            "Episode: 123, Alpha: 0.2699, Epsilon: 0.5398, Total Reward: 173.41\n",
            "After Episode 123: Q-Table Sample:\n",
            "[[2.35077189 2.22391898 2.29260757]\n",
            " [1.85581185 1.79335538 1.79678258]\n",
            " [2.46966743 2.46161873 2.52788126]\n",
            " [3.01673153 3.01574955 2.96938374]\n",
            " [2.14929499 2.17321043 2.21594286]]\n",
            "Episode: 124, Alpha: 0.2686, Epsilon: 0.5371, Total Reward: 173.41\n",
            "After Episode 124: Q-Table Sample:\n",
            "[[2.35406151 2.22391898 2.29260757]\n",
            " [1.85581185 1.81433801 1.79678258]\n",
            " [2.46966743 2.46161873 2.53271891]\n",
            " [3.02704782 3.01574955 2.96938374]\n",
            " [2.14929499 2.17321043 2.22572886]]\n",
            "Episode: 125, Alpha: 0.2672, Epsilon: 0.5344, Total Reward: 173.41\n",
            "After Episode 125: Q-Table Sample:\n",
            "[[2.35645566 2.22391898 2.29260757]\n",
            " [1.86122853 1.81433801 1.79678258]\n",
            " [2.4926551  2.46161873 2.53271891]\n",
            " [3.03704009 3.01574955 2.96938374]\n",
            " [2.14929499 2.17321043 2.23706515]]\n",
            "Episode: 126, Alpha: 0.2659, Epsilon: 0.5318, Total Reward: 173.41\n",
            "After Episode 126: Q-Table Sample:\n",
            "[[2.35956944 2.22391898 2.29260757]\n",
            " [1.86517796 1.81433801 1.79678258]\n",
            " [2.4926551  2.46161873 2.54135167]\n",
            " [3.04718903 3.01574955 2.96938374]\n",
            " [2.14929499 2.17321043 2.24533072]]\n",
            "Episode: 127, Alpha: 0.2645, Epsilon: 0.5291, Total Reward: 173.41\n",
            "After Episode 127: Q-Table Sample:\n",
            "[[2.35956944 2.22391898 2.31358911]\n",
            " [1.87023241 1.81433801 1.79678258]\n",
            " [2.4926551  2.46161873 2.55020812]\n",
            " [3.05667966 3.01574955 2.96938374]\n",
            " [2.14929499 2.17321043 2.25694194]]\n",
            "Episode: 128, Alpha: 0.2632, Epsilon: 0.5264, Total Reward: 173.41\n",
            "After Episode 128: Q-Table Sample:\n",
            "[[2.36408408 2.22391898 2.31358911]\n",
            " [1.8761458  1.81433801 1.79678258]\n",
            " [2.4926551  2.49379171 2.55020812]\n",
            " [3.05667966 3.03637186 2.96938374]\n",
            " [2.14929499 2.20374734 2.25694194]]\n",
            "Episode: 129, Alpha: 0.2619, Epsilon: 0.5238, Total Reward: 173.41\n",
            "After Episode 129: Q-Table Sample:\n",
            "[[2.36886504 2.22391898 2.31358911]\n",
            " [1.88048086 1.81433801 1.79678258]\n",
            " [2.4926551  2.49379171 2.55901803]\n",
            " [3.06647896 3.03637186 2.96938374]\n",
            " [2.14929499 2.20374734 2.26539628]]\n",
            "Episode: 130, Alpha: 0.2606, Epsilon: 0.5212, Total Reward: 173.41\n",
            "After Episode 130: Q-Table Sample:\n",
            "[[2.36886504 2.22391898 2.33257827]\n",
            " [1.88048086 1.83693942 1.79678258]\n",
            " [2.4926551  2.51968556 2.55901803]\n",
            " [3.06647896 3.05350735 2.96938374]\n",
            " [2.18961126 2.20374734 2.26539628]]\n",
            "Episode: 131, Alpha: 0.2593, Epsilon: 0.5186, Total Reward: 173.41\n",
            "After Episode 131: Q-Table Sample:\n",
            "[[2.36886504 2.26606417 2.33257827]\n",
            " [1.88581877 1.83693942 1.79678258]\n",
            " [2.4926551  2.51968556 2.56786957]\n",
            " [3.06647896 3.06611403 2.96938374]\n",
            " [2.22552213 2.20374734 2.26539628]]\n",
            "Episode: 132, Alpha: 0.2580, Epsilon: 0.5160, Total Reward: 173.41\n",
            "After Episode 132: Q-Table Sample:\n",
            "[[2.374712   2.26606417 2.33257827]\n",
            " [1.89192232 1.83693942 1.79678258]\n",
            " [2.4926551  2.51968556 2.57439317]\n",
            " [3.07567596 3.06611403 2.96938374]\n",
            " [2.25656364 2.20374734 2.26539628]]\n",
            "Episode: 133, Alpha: 0.2567, Epsilon: 0.5134, Total Reward: 173.41\n",
            "After Episode 133: Q-Table Sample:\n",
            "[[2.374712   2.29976021 2.33257827]\n",
            " [1.89192232 1.8571511  1.79678258]\n",
            " [2.4926551  2.51968556 2.58145239]\n",
            " [3.07567596 3.06611403 3.00345989]\n",
            " [2.25656364 2.24440478 2.26539628]]\n",
            "Episode: 134, Alpha: 0.2554, Epsilon: 0.5108, Total Reward: 173.41\n",
            "After Episode 134: Q-Table Sample:\n",
            "[[2.38048823 2.29976021 2.33257827]\n",
            " [1.8997019  1.8571511  1.79678258]\n",
            " [2.4926551  2.54068315 2.58145239]\n",
            " [3.08243207 3.06611403 3.00345989]\n",
            " [2.25656364 2.24440478 2.29377834]]\n",
            "Episode: 135, Alpha: 0.2541, Epsilon: 0.5083, Total Reward: 173.41\n",
            "After Episode 135: Q-Table Sample:\n",
            "[[2.38664586 2.29976021 2.33257827]\n",
            " [1.8997019  1.8571511  1.82870279]\n",
            " [2.4926551  2.54068315 2.5882783 ]\n",
            " [3.09428992 3.06611403 3.00345989]\n",
            " [2.25656364 2.24440478 2.31750929]]\n",
            "Episode: 136, Alpha: 0.2529, Epsilon: 0.5058, Total Reward: 173.41\n",
            "After Episode 136: Q-Table Sample:\n",
            "[[2.38664586 2.29976021 2.35082043]\n",
            " [1.8997019  1.87528573 1.82870279]\n",
            " [2.4926551  2.54068315 2.59619262]\n",
            " [3.10879086 3.06611403 3.00345989]\n",
            " [2.29157994 2.24440478 2.31750929]]\n",
            "Episode: 137, Alpha: 0.2516, Epsilon: 0.5032, Total Reward: 173.41\n",
            "After Episode 137: Q-Table Sample:\n",
            "[[2.39119274 2.29976021 2.35082043]\n",
            " [1.8997019  1.87528573 1.85579647]\n",
            " [2.4926551  2.54068315 2.60554221]\n",
            " [3.11957068 3.06611403 3.00345989]\n",
            " [2.29157994 2.24440478 2.33848768]]\n",
            "Episode: 138, Alpha: 0.2504, Epsilon: 0.5007, Total Reward: 173.41\n",
            "After Episode 138: Q-Table Sample:\n",
            "[[2.39457855 2.29976021 2.35082043]\n",
            " [1.91110885 1.87528573 1.85579647]\n",
            " [2.4926551  2.54068315 2.61506818]\n",
            " [3.13258726 3.06611403 3.00345989]\n",
            " [2.29157994 2.28545535 2.33848768]]\n",
            "Episode: 139, Alpha: 0.2491, Epsilon: 0.4982, Total Reward: 173.41\n",
            "After Episode 139: Q-Table Sample:\n",
            "[[2.39980344 2.29976021 2.35082043]\n",
            " [1.92187155 1.87528573 1.85579647]\n",
            " [2.4926551  2.54068315 2.62525391]\n",
            " [3.14229629 3.06611403 3.00345989]\n",
            " [2.29157994 2.28545535 2.35589671]]\n",
            "Episode: 140, Alpha: 0.2479, Epsilon: 0.4957, Total Reward: 173.41\n",
            "After Episode 140: Q-Table Sample:\n",
            "[[2.40624141 2.29976021 2.35082043]\n",
            " [1.93231121 1.87528573 1.85579647]\n",
            " [2.4926551  2.54068315 2.63515024]\n",
            " [3.15364953 3.06611403 3.00345989]\n",
            " [2.32052833 2.28545535 2.35589671]]\n",
            "Episode: 141, Alpha: 0.2466, Epsilon: 0.4932, Total Reward: 173.41\n",
            "After Episode 141: Q-Table Sample:\n",
            "[[2.41350535 2.29976021 2.35082043]\n",
            " [1.94244264 1.87528573 1.85579647]\n",
            " [2.4926551  2.54068315 2.64521639]\n",
            " [3.16214609 3.06611403 3.00345989]\n",
            " [2.32052833 2.28545535 2.3715824 ]]\n",
            "Episode: 142, Alpha: 0.2454, Epsilon: 0.4908, Total Reward: 173.41\n",
            "After Episode 142: Q-Table Sample:\n",
            "[[2.4213123  2.29976021 2.35082043]\n",
            " [1.94244264 1.90170626 1.85579647]\n",
            " [2.4926551  2.57586043 2.64521639]\n",
            " [3.17217182 3.06611403 3.00345989]\n",
            " [2.32052833 2.28545535 2.38600693]]\n",
            "Episode: 143, Alpha: 0.2442, Epsilon: 0.4883, Total Reward: 173.41\n",
            "After Episode 143: Q-Table Sample:\n",
            "[[2.4213123  2.29976021 2.37389336]\n",
            " [1.95233419 1.90170626 1.85579647]\n",
            " [2.4926551  2.60459848 2.64521639]\n",
            " [3.18304533 3.06611403 3.00345989]\n",
            " [2.32052833 2.32282504 2.38600693]]\n",
            "Episode: 144, Alpha: 0.2429, Epsilon: 0.4859, Total Reward: 173.41\n",
            "After Episode 144: Q-Table Sample:\n",
            "[[2.4213123  2.33740506 2.37389336]\n",
            " [1.95233419 1.90170626 1.88668812]\n",
            " [2.4926551  2.60459848 2.65947113]\n",
            " [3.18304533 3.06611403 3.05526539]\n",
            " [2.32052833 2.32282504 2.39876208]]\n",
            "Episode: 145, Alpha: 0.2417, Epsilon: 0.4834, Total Reward: 173.41\n",
            "After Episode 145: Q-Table Sample:\n",
            "[[2.4213123  2.33740506 2.39343035]\n",
            " [1.96300946 1.90170626 1.88668812]\n",
            " [2.4926551  2.60459848 2.6702089 ]\n",
            " [3.19411105 3.06611403 3.05526539]\n",
            " [2.32052833 2.32282504 2.41047046]]\n",
            "Episode: 146, Alpha: 0.2405, Epsilon: 0.4810, Total Reward: 173.41\n",
            "After Episode 146: Q-Table Sample:\n",
            "[[2.43178588 2.33740506 2.39343035]\n",
            " [1.96300946 1.90170626 1.91555225]\n",
            " [2.4926551  2.60459848 2.68083878]\n",
            " [3.20513521 3.06611403 3.05526539]\n",
            " [2.32052833 2.32282504 2.42140441]]\n",
            "Episode: 147, Alpha: 0.2393, Epsilon: 0.4786, Total Reward: 173.41\n",
            "After Episode 147: Q-Table Sample:\n",
            "[[2.43970064 2.33740506 2.39343035]\n",
            " [1.97588138 1.90170626 1.91555225]\n",
            " [2.54822873 2.60459848 2.68083878]\n",
            " [3.21595182 3.06611403 3.05526539]\n",
            " [2.32052833 2.32282504 2.43124366]]\n",
            "Episode: 148, Alpha: 0.2381, Epsilon: 0.4762, Total Reward: 173.41\n",
            "After Episode 148: Q-Table Sample:\n",
            "[[2.43970064 2.37066544 2.39343035]\n",
            " [1.97588138 1.90170626 1.93966006]\n",
            " [2.54822873 2.60459848 2.69377208]\n",
            " [3.22636449 3.06611403 3.05526539]\n",
            " [2.32052833 2.32282504 2.44036569]]\n",
            "Episode: 149, Alpha: 0.2369, Epsilon: 0.4738, Total Reward: 173.41\n",
            "After Episode 149: Q-Table Sample:\n",
            "[[2.43970064 2.37066544 2.41325069]\n",
            " [1.98848623 1.90170626 1.93966006]\n",
            " [2.59485952 2.60459848 2.69377208]\n",
            " [3.23631125 3.06611403 3.05526539]\n",
            " [2.32052833 2.32282504 2.44854221]]\n",
            "Episode: 150, Alpha: 0.2357, Epsilon: 0.4715, Total Reward: 173.41\n",
            "After Episode 150: Q-Table Sample:\n",
            "[[2.45133704 2.37066544 2.41325069]\n",
            " [1.98848623 1.93173409 1.93966006]\n",
            " [2.59485952 2.63993515 2.69377208]\n",
            " [3.24569458 3.06611403 3.05526539]\n",
            " [2.32052833 2.32282504 2.45609479]]\n",
            "Episode: 151, Alpha: 0.2346, Epsilon: 0.4691, Total Reward: 173.41\n",
            "After Episode 151: Q-Table Sample:\n",
            "[[2.46018581 2.37066544 2.41325069]\n",
            " [1.99800875 1.93173409 1.93966006]\n",
            " [2.59485952 2.63993515 2.71010637]\n",
            " [3.254513   3.06611403 3.05526539]\n",
            " [2.32052833 2.32282504 2.46183807]]\n",
            "Episode: 152, Alpha: 0.2334, Epsilon: 0.4668, Total Reward: 173.41\n",
            "After Episode 152: Q-Table Sample:\n",
            "[[2.46903646 2.37066544 2.41325069]\n",
            " [2.00888283 1.93173409 1.93966006]\n",
            " [2.59485952 2.63993515 2.72450196]\n",
            " [3.26250261 3.06611403 3.05526539]\n",
            " [2.32052833 2.32282504 2.46621222]]\n",
            "Episode: 153, Alpha: 0.2322, Epsilon: 0.4644, Total Reward: 173.41\n",
            "After Episode 153: Q-Table Sample:\n",
            "[[2.46903646 2.37066544 2.43535534]\n",
            " [2.02035316 1.93173409 1.93966006]\n",
            " [2.59485952 2.63993515 2.7372452 ]\n",
            " [3.26956189 3.06611403 3.05526539]\n",
            " [2.32052833 2.32282504 2.47054427]]\n",
            "Episode: 154, Alpha: 0.2311, Epsilon: 0.4621, Total Reward: 173.41\n",
            "After Episode 154: Q-Table Sample:\n",
            "[[2.46903646 2.40501712 2.43535534]\n",
            " [2.02035316 1.93173409 1.96986487]\n",
            " [2.59485952 2.63993515 2.74852984]\n",
            " [3.27590568 3.06611403 3.05526539]\n",
            " [2.32052833 2.36026644 2.47054427]]\n",
            "Episode: 155, Alpha: 0.2299, Epsilon: 0.4598, Total Reward: 173.41\n",
            "After Episode 155: Q-Table Sample:\n",
            "[[2.48060044 2.40501712 2.43535534]\n",
            " [2.0343199  1.93173409 1.96986487]\n",
            " [2.64020839 2.63993515 2.74852984]\n",
            " [3.28075928 3.06611403 3.05526539]\n",
            " [2.32052833 2.36026644 2.47383714]]\n",
            "Episode: 156, Alpha: 0.2288, Epsilon: 0.4575, Total Reward: 173.41\n",
            "After Episode 156: Q-Table Sample:\n",
            "[[2.49249649 2.40501712 2.43535534]\n",
            " [2.04502185 1.93173409 1.96986487]\n",
            " [2.64020839 2.63993515 2.75955388]\n",
            " [3.28519393 3.06611403 3.05526539]\n",
            " [2.35975499 2.36026644 2.47383714]]\n",
            "Episode: 157, Alpha: 0.2276, Epsilon: 0.4552, Total Reward: 173.41\n",
            "After Episode 157: Q-Table Sample:\n",
            "[[2.50393948 2.40501712 2.43535534]\n",
            " [2.05561814 1.93173409 1.96986487]\n",
            " [2.64020839 2.67658035 2.75955388]\n",
            " [3.28519393 3.11938217 3.05526539]\n",
            " [2.35975499 2.36026644 2.47951103]]\n",
            "Episode: 158, Alpha: 0.2265, Epsilon: 0.4529, Total Reward: 173.41\n",
            "After Episode 158: Q-Table Sample:\n",
            "[[2.51501351 2.40501712 2.43535534]\n",
            " [2.06376167 1.93173409 1.96986487]\n",
            " [2.64020839 2.70474317 2.75955388]\n",
            " [3.28980074 3.11938217 3.05526539]\n",
            " [2.35975499 2.36026644 2.48387156]]\n",
            "Episode: 159, Alpha: 0.2253, Epsilon: 0.4507, Total Reward: 173.41\n",
            "After Episode 159: Q-Table Sample:\n",
            "[[2.52528005 2.40501712 2.43535534]\n",
            " [2.07002942 1.93173409 1.96986487]\n",
            " [2.67741268 2.70474317 2.75955388]\n",
            " [3.29427989 3.11938217 3.05526539]\n",
            " [2.35975499 2.36026644 2.48860929]]\n",
            "Episode: 160, Alpha: 0.2242, Epsilon: 0.4484, Total Reward: 173.41\n",
            "After Episode 160: Q-Table Sample:\n",
            "[[2.52528005 2.44123012 2.43535534]\n",
            " [2.07486051 1.93173409 1.96986487]\n",
            " [2.67741268 2.70474317 2.77076728]\n",
            " [3.29874151 3.11938217 3.05526539]\n",
            " [2.35975499 2.36026644 2.49226106]]\n",
            "Episode: 161, Alpha: 0.2231, Epsilon: 0.4462, Total Reward: 173.41\n",
            "After Episode 161: Q-Table Sample:\n",
            "[[2.53550606 2.44123012 2.43535534]\n",
            " [2.08096621 1.93173409 1.96986487]\n",
            " [2.67741268 2.70474317 2.78036857]\n",
            " [3.30295942 3.11938217 3.05526539]\n",
            " [2.35975499 2.36026644 2.49641914]]\n",
            "Episode: 162, Alpha: 0.2220, Epsilon: 0.4440, Total Reward: 173.41\n",
            "After Episode 162: Q-Table Sample:\n",
            "[[2.54469856 2.44123012 2.43535534]\n",
            " [2.08771076 1.93173409 1.96986487]\n",
            " [2.67741268 2.70474317 2.78868005]\n",
            " [3.30709681 3.11938217 3.05526539]\n",
            " [2.39449517 2.36026644 2.49641914]]\n",
            "Episode: 163, Alpha: 0.2209, Epsilon: 0.4417, Total Reward: 173.41\n",
            "After Episode 163: Q-Table Sample:\n",
            "[[2.54469856 2.47261434 2.43535534]\n",
            " [2.09467589 1.93173409 1.96986487]\n",
            " [2.67741268 2.70474317 2.79598236]\n",
            " [3.31029969 3.11938217 3.05526539]\n",
            " [2.39449517 2.36026644 2.50189593]]\n",
            "Episode: 164, Alpha: 0.2198, Epsilon: 0.4395, Total Reward: 173.41\n",
            "After Episode 164: Q-Table Sample:\n",
            "[[2.55464143 2.47261434 2.43535534]\n",
            " [2.09467589 1.97446688 1.96986487]\n",
            " [2.67741268 2.70474317 2.80231206]\n",
            " [3.3139261  3.11938217 3.05526539]\n",
            " [2.39449517 2.36026644 2.50614175]]\n",
            "Episode: 165, Alpha: 0.2187, Epsilon: 0.4373, Total Reward: 173.41\n",
            "After Episode 165: Q-Table Sample:\n",
            "[[2.56236043 2.47261434 2.43535534]\n",
            " [2.1028803  1.97446688 1.96986487]\n",
            " [2.67741268 2.70474317 2.80797935]\n",
            " [3.3139261  3.11938217 3.11552262]\n",
            " [2.39449517 2.36026644 2.50943792]]\n",
            "Episode: 166, Alpha: 0.2176, Epsilon: 0.4351, Total Reward: 173.41\n",
            "After Episode 166: Q-Table Sample:\n",
            "[[2.5700572  2.47261434 2.43535534]\n",
            " [2.1028803  2.00995568 1.96986487]\n",
            " [2.67741268 2.70474317 2.81238526]\n",
            " [3.3139261  3.11938217 3.16304961]\n",
            " [2.39449517 2.36026644 2.51336285]]\n",
            "Episode: 167, Alpha: 0.2165, Epsilon: 0.4330, Total Reward: 173.41\n",
            "After Episode 167: Q-Table Sample:\n",
            "[[2.57604926 2.47261434 2.43535534]\n",
            " [2.1028803  2.03849042 1.96986487]\n",
            " [2.67741268 2.73147597 2.81238526]\n",
            " [3.3139261  3.1666432  3.16304961]\n",
            " [2.42451253 2.36026644 2.51336285]]\n",
            "Episode: 168, Alpha: 0.2154, Epsilon: 0.4308, Total Reward: 173.41\n",
            "After Episode 168: Q-Table Sample:\n",
            "[[2.58072067 2.47261434 2.43535534]\n",
            " [2.11125632 2.03849042 1.96986487]\n",
            " [2.67741268 2.75231683 2.81238526]\n",
            " [3.31904588 3.1666432  3.16304961]\n",
            " [2.42451253 2.36026644 2.51874758]]\n",
            "Episode: 169, Alpha: 0.2143, Epsilon: 0.4286, Total Reward: 173.41\n",
            "After Episode 169: Q-Table Sample:\n",
            "[[2.58072067 2.50113639 2.43535534]\n",
            " [2.11779527 2.03849042 1.96986487]\n",
            " [2.67741268 2.76962922 2.81238526]\n",
            " [3.32413914 3.1666432  3.16304961]\n",
            " [2.42451253 2.36026644 2.52397907]]\n",
            "Episode: 170, Alpha: 0.2133, Epsilon: 0.4265, Total Reward: 173.41\n",
            "After Episode 170: Q-Table Sample:\n",
            "[[2.58737091 2.50113639 2.43535534]\n",
            " [2.11779527 2.06051418 1.96986487]\n",
            " [2.67741268 2.76962922 2.8178332 ]\n",
            " [3.32413914 3.20527106 3.16304961]\n",
            " [2.42451253 2.39926825 2.52397907]]\n",
            "Episode: 171, Alpha: 0.2122, Epsilon: 0.4244, Total Reward: 173.41\n",
            "After Episode 171: Q-Table Sample:\n",
            "[[2.59257681 2.50113639 2.43535534]\n",
            " [2.12397971 2.06051418 1.96986487]\n",
            " [2.67741268 2.76962922 2.82209793]\n",
            " [3.32413914 3.20527106 3.20224685]\n",
            " [2.42451253 2.39926825 2.52804833]]\n",
            "Episode: 172, Alpha: 0.2111, Epsilon: 0.4223, Total Reward: 173.41\n",
            "After Episode 172: Q-Table Sample:\n",
            "[[2.59789799 2.50113639 2.43535534]\n",
            " [2.1296829  2.06051418 1.96986487]\n",
            " [2.67741268 2.76962922 2.82544094]\n",
            " [3.32994651 3.20527106 3.20224685]\n",
            " [2.45071166 2.39926825 2.52804833]]\n",
            "Episode: 173, Alpha: 0.2101, Epsilon: 0.4201, Total Reward: 173.41\n",
            "After Episode 173: Q-Table Sample:\n",
            "[[2.60321291 2.50113639 2.43535534]\n",
            " [2.13482666 2.06051418 1.96986487]\n",
            " [2.71229188 2.76962922 2.82544094]\n",
            " [3.3345049  3.20527106 3.20224685]\n",
            " [2.45071166 2.39926825 2.5333606 ]]\n",
            "Episode: 174, Alpha: 0.2090, Epsilon: 0.4180, Total Reward: 173.41\n",
            "After Episode 174: Q-Table Sample:\n",
            "[[2.60841172 2.50113639 2.43535534]\n",
            " [2.13886955 2.06051418 1.96986487]\n",
            " [2.71229188 2.76962922 2.83011016]\n",
            " [3.3345049  3.23692106 3.20224685]\n",
            " [2.47216221 2.39926825 2.5333606 ]]\n",
            "Episode: 175, Alpha: 0.2080, Epsilon: 0.4159, Total Reward: 173.41\n",
            "After Episode 175: Q-Table Sample:\n",
            "[[2.61330209 2.50113639 2.43535534]\n",
            " [2.14297394 2.06051418 1.96986487]\n",
            " [2.74046982 2.76962922 2.83011016]\n",
            " [3.3345049  3.26183042 3.20224685]\n",
            " [2.47216221 2.39926825 2.53840802]]\n",
            "Episode: 176, Alpha: 0.2069, Epsilon: 0.4139, Total Reward: 173.41\n",
            "After Episode 176: Q-Table Sample:\n",
            "[[2.6179629  2.50113639 2.43535534]\n",
            " [2.14620847 2.06051418 1.96986487]\n",
            " [2.76267589 2.76962922 2.83011016]\n",
            " [3.34008854 3.26183042 3.20224685]\n",
            " [2.49054769 2.39926825 2.53840802]]\n",
            "Episode: 177, Alpha: 0.2059, Epsilon: 0.4118, Total Reward: 173.41\n",
            "After Episode 177: Q-Table Sample:\n",
            "[[2.62227344 2.50113639 2.43535534]\n",
            " [2.14620847 2.06051418 2.00872629]\n",
            " [2.7812909  2.76962922 2.83011016]\n",
            " [3.3444946  3.26183042 3.20224685]\n",
            " [2.49054769 2.39926825 2.54306159]]\n",
            "Episode: 178, Alpha: 0.2049, Epsilon: 0.4097, Total Reward: 173.41\n",
            "After Episode 178: Q-Table Sample:\n",
            "[[2.62567932 2.50113639 2.43535534]\n",
            " [2.14874807 2.06051418 2.00872629]\n",
            " [2.7812909  2.76962922 2.83567437]\n",
            " [3.34888167 3.26183042 3.20224685]\n",
            " [2.49054769 2.39926825 2.54673852]]\n",
            "Episode: 179, Alpha: 0.2038, Epsilon: 0.4077, Total Reward: 173.41\n",
            "After Episode 179: Q-Table Sample:\n",
            "[[2.62567932 2.52971031 2.43535534]\n",
            " [2.15183482 2.06051418 2.00872629]\n",
            " [2.7812909  2.76962922 2.84092609]\n",
            " [3.34888167 3.28375834 3.20224685]\n",
            " [2.49054769 2.39926825 2.55040666]]\n",
            "Episode: 180, Alpha: 0.2028, Epsilon: 0.4057, Total Reward: 173.41\n",
            "After Episode 180: Q-Table Sample:\n",
            "[[2.62567932 2.52971031 2.47772329]\n",
            " [2.15183482 2.08249359 2.00872629]\n",
            " [2.7812909  2.76962922 2.84508636]\n",
            " [3.34888167 3.28375834 3.23685704]\n",
            " [2.49054769 2.39926825 2.55391004]]\n",
            "Episode: 181, Alpha: 0.2018, Epsilon: 0.4036, Total Reward: 173.41\n",
            "After Episode 181: Q-Table Sample:\n",
            "[[2.62942572 2.52971031 2.47772329]\n",
            " [2.15607232 2.08249359 2.00872629]\n",
            " [2.79746549 2.76962922 2.84508636]\n",
            " [3.35439778 3.28375834 3.23685704]\n",
            " [2.49054769 2.39926825 2.55668888]]\n",
            "Episode: 182, Alpha: 0.2008, Epsilon: 0.4016, Total Reward: 173.41\n",
            "After Episode 182: Q-Table Sample:\n",
            "[[2.63320945 2.52971031 2.47772329]\n",
            " [2.15943773 2.08249359 2.00872629]\n",
            " [2.79746549 2.76962922 2.84942201]\n",
            " [3.35930875 3.28375834 3.23685704]\n",
            " [2.49054769 2.43308576 2.55668888]]\n",
            "Episode: 183, Alpha: 0.1998, Epsilon: 0.3996, Total Reward: 173.41\n",
            "After Episode 183: Q-Table Sample:\n",
            "[[2.63685706 2.52971031 2.47772329]\n",
            " [2.15943773 2.08249359 2.04233744]\n",
            " [2.79746549 2.76962922 2.85380187]\n",
            " [3.35930875 3.30275846 3.23685704]\n",
            " [2.49054769 2.43308576 2.55888478]]\n",
            "Episode: 184, Alpha: 0.1988, Epsilon: 0.3976, Total Reward: 173.41\n",
            "After Episode 184: Q-Table Sample:\n",
            "[[2.63976129 2.52971031 2.47772329]\n",
            " [2.16374653 2.08249359 2.04233744]\n",
            " [2.81215242 2.76962922 2.85380187]\n",
            " [3.36360916 3.30275846 3.23685704]\n",
            " [2.49054769 2.43308576 2.56139235]]\n",
            "Episode: 185, Alpha: 0.1978, Epsilon: 0.3956, Total Reward: 173.41\n",
            "After Episode 185: Q-Table Sample:\n",
            "[[2.63976129 2.52971031 2.51290034]\n",
            " [2.16374653 2.10200088 2.04233744]\n",
            " [2.81215242 2.76962922 2.85807979]\n",
            " [3.36750863 3.30275846 3.23685704]\n",
            " [2.49054769 2.43308576 2.56408697]]\n",
            "Episode: 186, Alpha: 0.1968, Epsilon: 0.3936, Total Reward: 173.41\n",
            "After Episode 186: Q-Table Sample:\n",
            "[[2.63976129 2.52971031 2.54097806]\n",
            " [2.16796418 2.10200088 2.04233744]\n",
            " [2.81215242 2.76962922 2.86222346]\n",
            " [3.36750863 3.30275846 3.26618784]\n",
            " [2.49054769 2.43308576 2.56678953]]\n",
            "Episode: 187, Alpha: 0.1958, Epsilon: 0.3917, Total Reward: 173.41\n",
            "After Episode 187: Q-Table Sample:\n",
            "[[2.6436397  2.52971031 2.54097806]\n",
            " [2.17210568 2.10200088 2.04233744]\n",
            " [2.81215242 2.76962922 2.86553495]\n",
            " [3.37160965 3.30275846 3.26618784]\n",
            " [2.49054769 2.43308576 2.56894932]]\n",
            "Episode: 188, Alpha: 0.1949, Epsilon: 0.3897, Total Reward: 173.41\n",
            "After Episode 188: Q-Table Sample:\n",
            "[[2.6436397  2.55577983 2.54097806]\n",
            " [2.17603248 2.10200088 2.04233744]\n",
            " [2.81215242 2.76962922 2.86894377]\n",
            " [3.37529087 3.30275846 3.26618784]\n",
            " [2.49054769 2.46128746 2.56894932]]\n",
            "Episode: 189, Alpha: 0.1939, Epsilon: 0.3878, Total Reward: 173.41\n",
            "After Episode 189: Q-Table Sample:\n",
            "[[2.64821355 2.55577983 2.54097806]\n",
            " [2.17603248 2.10200088 2.07203188]\n",
            " [2.81215242 2.7922932  2.86894377]\n",
            " [3.37823997 3.30275846 3.26618784]\n",
            " [2.49054769 2.46128746 2.57126315]]\n",
            "Episode: 190, Alpha: 0.1929, Epsilon: 0.3858, Total Reward: 173.41\n",
            "After Episode 190: Q-Table Sample:\n",
            "[[2.64821355 2.57727988 2.54097806]\n",
            " [2.1797873  2.10200088 2.07203188]\n",
            " [2.81215242 2.7922932  2.87287609]\n",
            " [3.38102946 3.30275846 3.26618784]\n",
            " [2.49054769 2.46128746 2.57365802]]\n",
            "Episode: 191, Alpha: 0.1919, Epsilon: 0.3839, Total Reward: 173.41\n",
            "After Episode 191: Q-Table Sample:\n",
            "[[2.65254852 2.57727988 2.54097806]\n",
            " [2.1797873  2.12066403 2.07203188]\n",
            " [2.81215242 2.7922932  2.87654262]\n",
            " [3.38370627 3.30275846 3.26618784]\n",
            " [2.49054769 2.46128746 2.57606313]]\n",
            "Episode: 192, Alpha: 0.1910, Epsilon: 0.3820, Total Reward: 173.41\n",
            "After Episode 192: Q-Table Sample:\n",
            "[[2.65254852 2.59514052 2.54097806]\n",
            " [2.18416627 2.12066403 2.07203188]\n",
            " [2.81215242 2.7922932  2.87997623]\n",
            " [3.38629484 3.30275846 3.26618784]\n",
            " [2.49054769 2.46128746 2.57843161]]\n",
            "Episode: 193, Alpha: 0.1900, Epsilon: 0.3801, Total Reward: 173.41\n",
            "After Episode 193: Q-Table Sample:\n",
            "[[2.65680701 2.59514052 2.54097806]\n",
            " [2.18416627 2.12066403 2.09748569]\n",
            " [2.81215242 2.7922932  2.88320749]\n",
            " [3.38880613 3.30275846 3.26618784]\n",
            " [2.49054769 2.46128746 2.58073222]]\n",
            "Episode: 194, Alpha: 0.1891, Epsilon: 0.3782, Total Reward: 173.41\n",
            "After Episode 194: Q-Table Sample:\n",
            "[[2.66023901 2.59514052 2.54097806]\n",
            " [2.18887076 2.12066403 2.09748569]\n",
            " [2.81215242 2.7922932  2.88626272]\n",
            " [3.39124329 3.30275846 3.26618784]\n",
            " [2.49054769 2.46128746 2.58294512]]\n",
            "Episode: 195, Alpha: 0.1881, Epsilon: 0.3763, Total Reward: 173.41\n",
            "After Episode 195: Q-Table Sample:\n",
            "[[2.66023901 2.61099784 2.54097806]\n",
            " [2.19321271 2.12066403 2.09748569]\n",
            " [2.81215242 2.7922932  2.88916347]\n",
            " [3.39124329 3.30275846 3.29207717]\n",
            " [2.49054769 2.46128746 2.58505274]]\n",
            "Episode: 196, Alpha: 0.1872, Epsilon: 0.3744, Total Reward: 173.41\n",
            "After Episode 196: Q-Table Sample:\n",
            "[[2.66460309 2.61099784 2.54097806]\n",
            " [2.19723601 2.12066403 2.09748569]\n",
            " [2.81215242 2.7922932  2.89150671]\n",
            " [3.39124329 3.30275846 3.31336551]\n",
            " [2.49054769 2.46128746 2.58701388]]\n",
            "Episode: 197, Alpha: 0.1863, Epsilon: 0.3725, Total Reward: 173.41\n",
            "After Episode 197: Q-Table Sample:\n",
            "[[2.66884441 2.61099784 2.54097806]\n",
            " [2.19723601 2.12066403 2.11973351]\n",
            " [2.81215242 2.7922932  2.89340178]\n",
            " [3.39430164 3.30275846 3.31336551]\n",
            " [2.51010143 2.46128746 2.58701388]]\n",
            "Episode: 198, Alpha: 0.1853, Epsilon: 0.3707, Total Reward: 173.41\n",
            "After Episode 198: Q-Table Sample:\n",
            "[[2.6722785  2.61099784 2.54097806]\n",
            " [2.19723601 2.13883867 2.11973351]\n",
            " [2.81215242 2.81310425 2.89340178]\n",
            " [3.3967779  3.30275846 3.31336551]\n",
            " [2.51010143 2.46128746 2.58859201]]\n",
            "Episode: 199, Alpha: 0.1844, Epsilon: 0.3688, Total Reward: 173.41\n",
            "After Episode 199: Q-Table Sample:\n",
            "[[2.6722785  2.61099784 2.56797364]\n",
            " [2.20119983 2.13883867 2.11973351]\n",
            " [2.81215242 2.81310425 2.89589806]\n",
            " [3.39906162 3.30275846 3.31336551]\n",
            " [2.51010143 2.46128746 2.58987125]]\n",
            "Running Code on Test Data\n",
            "Test Data saved with recommendations\n",
            "            Correct Predictions  Wrong Predictions\n",
            "Buy Long                   7885               7754\n",
            "Sell Short                 7785               7947\n",
            "Hold                      12521               3120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LuXcdF4oGj2K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}